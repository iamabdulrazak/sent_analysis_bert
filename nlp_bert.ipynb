{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp_bert.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7a215455771046589cb5b902c60fcab9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_db53a509101d43ddb1575d603af66265",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f151b9be13af4627bcc50cbeea141a6c",
              "IPY_MODEL_a3dfa3e6438a4c6dba1d6013000bffa7"
            ]
          }
        },
        "db53a509101d43ddb1575d603af66265": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f151b9be13af4627bcc50cbeea141a6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_80f003d793b54069ae5cb91a91e7cc5c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_58360b8573ab463d978564901c9b79d7"
          }
        },
        "a3dfa3e6438a4c6dba1d6013000bffa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a35f6d44d5c44feeb31cb6cc50470bef",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 935kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2111d358e9a447b09d273d212407fe04"
          }
        },
        "80f003d793b54069ae5cb91a91e7cc5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "58360b8573ab463d978564901c9b79d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a35f6d44d5c44feeb31cb6cc50470bef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2111d358e9a447b09d273d212407fe04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "11cb8f0d4260426dacbad1dc5537c4c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_78a65dd69270484cba6051b8a84b08c3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7e6852a183fd4198934bfeb1ed64f5d8",
              "IPY_MODEL_c6b3f612d9db4e7eb9e44b791523544e"
            ]
          }
        },
        "78a65dd69270484cba6051b8a84b08c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7e6852a183fd4198934bfeb1ed64f5d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b7b1499871e04193aa6fb9d999cbfa01",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ef61b0b322d3442bb372707177e4f38b"
          }
        },
        "c6b3f612d9db4e7eb9e44b791523544e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_670b88be52584b8697da1fc4bef93c5c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 3.21kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4f9b122b5b774942b1d78be6f38eaca5"
          }
        },
        "b7b1499871e04193aa6fb9d999cbfa01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ef61b0b322d3442bb372707177e4f38b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "670b88be52584b8697da1fc4bef93c5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4f9b122b5b774942b1d78be6f38eaca5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "31e90090b7a2459fa192b28f5e507920": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d538ca255a1b4cbbaf7be939e53b96f3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fd8cd4480be541ac93fa6f2584d665a0",
              "IPY_MODEL_86b90cb67b9f44f18b370b1ec493c15c"
            ]
          }
        },
        "d538ca255a1b4cbbaf7be939e53b96f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fd8cd4480be541ac93fa6f2584d665a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1ee32ba4fa1541bf9985c3647b19bff4",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c24ca96456fc483b9c154fcf3ac85b81"
          }
        },
        "86b90cb67b9f44f18b370b1ec493c15c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_081de41ae0eb4628b0cd001da20768b0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [01:21&lt;00:00, 5.39MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5a8f6642f9d448c69b15dc14336d34f8"
          }
        },
        "1ee32ba4fa1541bf9985c3647b19bff4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c24ca96456fc483b9c154fcf3ac85b81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "081de41ae0eb4628b0cd001da20768b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5a8f6642f9d448c69b15dc14336d34f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xa-1LH2xJQEv"
      },
      "source": [
        "# EDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiLQIM3Tuw_B"
      },
      "source": [
        "try:\n",
        "  import torch\n",
        "  import pandas as pd\n",
        "  import tqdm\n",
        "except Exception as e:\n",
        "  print('Package Missing! \\n\\n {}'.format(e))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P58sexWeuxDK",
        "outputId": "d2e019ed-8be8-4c97-80fb-32663631a3d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        }
      },
      "source": [
        "df = pd.read_csv('data/smile.csv',names=['id','text','category'])\n",
        "df.set_index('id',inplace=True)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>611857364396965889</th>\n",
              "      <td>@aandraous @britishmuseum @AndrewsAntonio Merc...</td>\n",
              "      <td>nocode</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>614484565059596288</th>\n",
              "      <td>Dorian Gray with Rainbow Scarf #LoveWins (from...</td>\n",
              "      <td>happy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>614746522043973632</th>\n",
              "      <td>@SelectShowcase @Tate_StIves ... Replace with ...</td>\n",
              "      <td>happy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>614877582664835073</th>\n",
              "      <td>@Sofabsports thank you for following me back. ...</td>\n",
              "      <td>happy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>611932373039644672</th>\n",
              "      <td>@britishmuseum @TudorHistory What a beautiful ...</td>\n",
              "      <td>happy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                 text category\n",
              "id                                                                            \n",
              "611857364396965889  @aandraous @britishmuseum @AndrewsAntonio Merc...   nocode\n",
              "614484565059596288  Dorian Gray with Rainbow Scarf #LoveWins (from...    happy\n",
              "614746522043973632  @SelectShowcase @Tate_StIves ... Replace with ...    happy\n",
              "614877582664835073  @Sofabsports thank you for following me back. ...    happy\n",
              "611932373039644672  @britishmuseum @TudorHistory What a beautiful ...    happy"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6EY5wTKw2Ut",
        "outputId": "c4299463-0582-4f3a-f1ba-1f332af12ee1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text        0\n",
              "category    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x41_Z1Xjs3Sa",
        "outputId": "0ff42e42-cfa5-4515-e342-1b9ea145bdd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3085, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFRYHv4puxOz",
        "outputId": "05c6540d-c4b0-4f3d-b741-7669584bfbbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "df.text.iloc[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'@aandraous @britishmuseum @AndrewsAntonio Merci pour le partage! @openwinemap'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ro1GgECHuxY6",
        "outputId": "679dd890-b958-4568-b452-93e851c65c33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "source": [
        "df.category.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "nocode               1572\n",
              "happy                1137\n",
              "not-relevant          214\n",
              "angry                  57\n",
              "surprise               35\n",
              "sad                    32\n",
              "happy|surprise         11\n",
              "happy|sad               9\n",
              "disgust|angry           7\n",
              "disgust                 6\n",
              "sad|angry               2\n",
              "sad|disgust             2\n",
              "sad|disgust|angry       1\n",
              "Name: category, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXmxf4EDuxgk"
      },
      "source": [
        "df = df[~df.category.str.contains('\\|')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7w9UNilUuxxr",
        "outputId": "e97047f3-b59a-48d4-a8dd-3912d133affa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        }
      },
      "source": [
        "df.category.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "nocode          1572\n",
              "happy           1137\n",
              "not-relevant     214\n",
              "angry             57\n",
              "surprise          35\n",
              "sad               32\n",
              "disgust            6\n",
              "Name: category, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHHXRqv3uxtn"
      },
      "source": [
        "df = df[df.category != 'nocode']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jevZMY-uuxrz",
        "outputId": "c7d79d0e-ad0f-424f-ef2d-848c49a8394a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "df.category.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "happy           1137\n",
              "not-relevant     214\n",
              "angry             57\n",
              "surprise          35\n",
              "sad               32\n",
              "disgust            6\n",
              "Name: category, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89rmQUpXuxoU"
      },
      "source": [
        "possible_labels = df.category.unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJK2aviAuxl5"
      },
      "source": [
        "label_dic={}\n",
        "for index,possible_label in enumerate (possible_labels):\n",
        "  label_dic[possible_label]=index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwGy6_qYuxjH",
        "outputId": "c880bd5d-ccc2-42f6-edf6-ba0b2a16b7da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        }
      },
      "source": [
        "label_dic"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'angry': 2,\n",
              " 'disgust': 3,\n",
              " 'happy': 0,\n",
              " 'not-relevant': 1,\n",
              " 'sad': 4,\n",
              " 'surprise': 5}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_tLjVqouxdx",
        "outputId": "263bdd88-2864-48b9-bda6-7d2952c3b3e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        }
      },
      "source": [
        "df['label'] = df.category.replace(label_dic)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>614484565059596288</th>\n",
              "      <td>Dorian Gray with Rainbow Scarf #LoveWins (from...</td>\n",
              "      <td>happy</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>614746522043973632</th>\n",
              "      <td>@SelectShowcase @Tate_StIves ... Replace with ...</td>\n",
              "      <td>happy</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>614877582664835073</th>\n",
              "      <td>@Sofabsports thank you for following me back. ...</td>\n",
              "      <td>happy</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>611932373039644672</th>\n",
              "      <td>@britishmuseum @TudorHistory What a beautiful ...</td>\n",
              "      <td>happy</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>611570404268883969</th>\n",
              "      <td>@NationalGallery @ThePoldarkian I have always ...</td>\n",
              "      <td>happy</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                 text  ... label\n",
              "id                                                                     ...      \n",
              "614484565059596288  Dorian Gray with Rainbow Scarf #LoveWins (from...  ...     0\n",
              "614746522043973632  @SelectShowcase @Tate_StIves ... Replace with ...  ...     0\n",
              "614877582664835073  @Sofabsports thank you for following me back. ...  ...     0\n",
              "611932373039644672  @britishmuseum @TudorHistory What a beautiful ...  ...     0\n",
              "611570404268883969  @NationalGallery @ThePoldarkian I have always ...  ...     0\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdrenx2l9RA1"
      },
      "source": [
        "#Training, Testing, Validation etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otAVtUeduxWP"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKp4eWfJuxUX"
      },
      "source": [
        "X_train,X_val,y_train,y_val=train_test_split(\n",
        "   df.index.values,\n",
        "   df.label.values,\n",
        "   test_size=0.15,\n",
        "   random_state=17,\n",
        "   stratify=df.label.values\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRbn8NliuxSS",
        "outputId": "897702c1-d3ec-421c-c792-58166ef3c602",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1481, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jz7ClN0kuxM8",
        "outputId": "3cf73b82-31aa-4e0a-d6bf-a471137965c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        }
      },
      "source": [
        "df['data_type'] = ['not_set']*df.shape[0]\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "      <th>label</th>\n",
              "      <th>data_type</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>614484565059596288</th>\n",
              "      <td>Dorian Gray with Rainbow Scarf #LoveWins (from...</td>\n",
              "      <td>happy</td>\n",
              "      <td>0</td>\n",
              "      <td>not_set</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>614746522043973632</th>\n",
              "      <td>@SelectShowcase @Tate_StIves ... Replace with ...</td>\n",
              "      <td>happy</td>\n",
              "      <td>0</td>\n",
              "      <td>not_set</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>614877582664835073</th>\n",
              "      <td>@Sofabsports thank you for following me back. ...</td>\n",
              "      <td>happy</td>\n",
              "      <td>0</td>\n",
              "      <td>not_set</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>611932373039644672</th>\n",
              "      <td>@britishmuseum @TudorHistory What a beautiful ...</td>\n",
              "      <td>happy</td>\n",
              "      <td>0</td>\n",
              "      <td>not_set</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>611570404268883969</th>\n",
              "      <td>@NationalGallery @ThePoldarkian I have always ...</td>\n",
              "      <td>happy</td>\n",
              "      <td>0</td>\n",
              "      <td>not_set</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                 text  ... data_type\n",
              "id                                                                     ...          \n",
              "614484565059596288  Dorian Gray with Rainbow Scarf #LoveWins (from...  ...   not_set\n",
              "614746522043973632  @SelectShowcase @Tate_StIves ... Replace with ...  ...   not_set\n",
              "614877582664835073  @Sofabsports thank you for following me back. ...  ...   not_set\n",
              "611932373039644672  @britishmuseum @TudorHistory What a beautiful ...  ...   not_set\n",
              "611570404268883969  @NationalGallery @ThePoldarkian I have always ...  ...   not_set\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5oPswLbuxCI"
      },
      "source": [
        "df.loc[X_train, 'data_type'] = 'train'\n",
        "df.loc[X_val, 'data_type'] = 'val'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kyb_18X8_zA",
        "outputId": "f44c0736-b9e5-47dc-e266-0cf5fb4de189",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        }
      },
      "source": [
        "df.groupby(['category','label','data_type']).count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>category</th>\n",
              "      <th>label</th>\n",
              "      <th>data_type</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">angry</th>\n",
              "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
              "      <th>train</th>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>val</th>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">disgust</th>\n",
              "      <th rowspan=\"2\" valign=\"top\">3</th>\n",
              "      <th>train</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>val</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">happy</th>\n",
              "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
              "      <th>train</th>\n",
              "      <td>966</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>val</th>\n",
              "      <td>171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">not-relevant</th>\n",
              "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
              "      <th>train</th>\n",
              "      <td>182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>val</th>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">sad</th>\n",
              "      <th rowspan=\"2\" valign=\"top\">4</th>\n",
              "      <th>train</th>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>val</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">surprise</th>\n",
              "      <th rowspan=\"2\" valign=\"top\">5</th>\n",
              "      <th>train</th>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>val</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              text\n",
              "category     label data_type      \n",
              "angry        2     train        48\n",
              "                   val           9\n",
              "disgust      3     train         5\n",
              "                   val           1\n",
              "happy        0     train       966\n",
              "                   val         171\n",
              "not-relevant 1     train       182\n",
              "                   val          32\n",
              "sad          4     train        27\n",
              "                   val           5\n",
              "surprise     5     train        30\n",
              "                   val           5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZKF_YZgipaa",
        "outputId": "275bd37c-377b-4bce-fd57-d39e22ac4db5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        }
      },
      "source": [
        "!pip install transformers tokenizer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/22/aff234f4a841f8999e68a7a94bdd4b60b4cebcfeca5d67d61cd08c9179de/transformers-3.3.1-py3-none-any.whl (1.1MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1MB 5.2MB/s \n",
            "\u001b[?25hCollecting tokenizer\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/88/76356c78aef6b527db91362ed92a0da2d18a0271921d79559fc0bc8c49c3/tokenizer-2.4.0-py2.py3-none-any.whl (105kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 112kB 28.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 22.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1MB 37.6MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.8.1.rc2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/83/8b9fccb9e48eeb575ee19179e2bdde0ee9a1904f97de5f02d19016b8804f/tokenizers-0.8.1rc2-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.0MB 57.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=e39694c249a5627b0d547dfd1f46ecbae6e339f00449fc7d2f8539a2ffa73c9b\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers, tokenizer\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizer-2.4.0 tokenizers-0.8.1rc2 transformers-3.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnQeXjLrhNbN"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "from torch.utils.data import TensorDataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l11pzI0phNeF",
        "outputId": "b486561e-8e78-4f61-f246-80c2c7c9097b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65,
          "referenced_widgets": [
            "7a215455771046589cb5b902c60fcab9",
            "db53a509101d43ddb1575d603af66265",
            "f151b9be13af4627bcc50cbeea141a6c",
            "a3dfa3e6438a4c6dba1d6013000bffa7",
            "80f003d793b54069ae5cb91a91e7cc5c",
            "58360b8573ab463d978564901c9b79d7",
            "a35f6d44d5c44feeb31cb6cc50470bef",
            "2111d358e9a447b09d273d212407fe04"
          ]
        }
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\n",
        "    'bert-base-uncased',\n",
        "    do_lower_case=True\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7a215455771046589cb5b902c60fcab9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6nrO3xchNlP",
        "outputId": "9934a3d7-136f-4139-8186-591d403a7bf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "encoded_data_train = tokenizer.batch_encode_plus(\n",
        "    df[df.data_type == 'train'].text.values,\n",
        "    add_special_tokens=True,\n",
        "    return_attention_mask=True,\n",
        "    pad_to_max_length=True,\n",
        "    max_length=256,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "encoded_data_val = tokenizer.batch_encode_plus(\n",
        "    df[df.data_type =='val'].text.values,\n",
        "    add_special_tokens=True,\n",
        "    return_attention_mask=True,\n",
        "    pad_to_max_length=True,\n",
        "    max_length=256,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "\n",
        "input_ids_train = encoded_data_train['input_ids']\n",
        "attention_mask_train = encoded_data_train['attention_mask']\n",
        "labels_train=torch.tensor(df[df.data_type == 'train'].label.values)\n",
        "\n",
        "\n",
        "input_ids_val = encoded_data_val['input_ids']\n",
        "attention_mask_val = encoded_data_val['attention_mask']\n",
        "labels_val=torch.tensor(df[df.data_type == 'val'].label.values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1773: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGRKgbUBzADu"
      },
      "source": [
        "dataset_train = TensorDataset(input_ids_train,attention_mask_train,labels_train)\n",
        "dataset_val = TensorDataset(input_ids_val,attention_mask_val,labels_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKrP4ij1hNwj",
        "outputId": "f5b28e1f-02cc-4800-dcbb-32460bcbddf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print('Dataset_Train: {} \\nDataset_Val: {}'.format(len(dataset_train), len(dataset_val)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset_Train: 1258 \n",
            "Dataset_Val: 223\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scNSOT1nsj81"
      },
      "source": [
        "\n",
        "#Bert, Transformers, Optimization etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPZnxu7UhOGG"
      },
      "source": [
        "from transformers import BertForSequenceClassification"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2br8A8UThOJu",
        "outputId": "ce66ea50-7940-44f7-f443-66a485f0d890",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "11cb8f0d4260426dacbad1dc5537c4c6",
            "78a65dd69270484cba6051b8a84b08c3",
            "7e6852a183fd4198934bfeb1ed64f5d8",
            "c6b3f612d9db4e7eb9e44b791523544e",
            "b7b1499871e04193aa6fb9d999cbfa01",
            "ef61b0b322d3442bb372707177e4f38b",
            "670b88be52584b8697da1fc4bef93c5c",
            "4f9b122b5b774942b1d78be6f38eaca5",
            "31e90090b7a2459fa192b28f5e507920",
            "d538ca255a1b4cbbaf7be939e53b96f3",
            "fd8cd4480be541ac93fa6f2584d665a0",
            "86b90cb67b9f44f18b370b1ec493c15c",
            "1ee32ba4fa1541bf9985c3647b19bff4",
            "c24ca96456fc483b9c154fcf3ac85b81",
            "081de41ae0eb4628b0cd001da20768b0",
            "5a8f6642f9d448c69b15dc14336d34f8"
          ]
        }
      },
      "source": [
        "model=BertForSequenceClassification.from_pretrained(\n",
        "    'bert-base-uncased',\n",
        "    num_labels=len(label_dic),\n",
        "    output_attentions=False,\n",
        "    output_hidden_states=False\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "11cb8f0d4260426dacbad1dc5537c4c6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "31e90090b7a2459fa192b28f5e507920",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUnIQRESqw9O"
      },
      "source": [
        "from torch.utils.data import DataLoader,RandomSampler,SequentialSampler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxz8DMTHrDMR"
      },
      "source": [
        "batch_size=32\n",
        "\n",
        "dataloader_train=DataLoader(\n",
        "    dataset_train,\n",
        "    sampler=RandomSampler(dataset_train),\n",
        "    batch_size=batch_size\n",
        ")\n",
        "dataloader_val=DataLoader(\n",
        "    dataset_val,\n",
        "    sampler=RandomSampler(dataset_val),\n",
        "    batch_size=batch_size\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckionvywhODI"
      },
      "source": [
        "from transformers import AdamW ,get_linear_schedule_with_warmup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOqYcXjChOA5"
      },
      "source": [
        "optimizer = AdamW(\n",
        "    model.parameters(),\n",
        "    lr=1e-5 ,\n",
        "    eps=1e-8\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnFd1o57hN_D"
      },
      "source": [
        "epochs=10\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=len(dataloader_train)*epochs\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCNhvBY-hN4Z"
      },
      "source": [
        "import numpy  as np\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNjOAknBhNzh"
      },
      "source": [
        "def f1_score_func(preds,labels):\n",
        "  preds_flat=np.argmax(preds,axis=1).flatten()\n",
        "  labels_flat=labels.flatten()\n",
        "  return f1_score(labels_flat,preds_flat,average='weighted')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlGoDIxPhNuS"
      },
      "source": [
        "def accuracy_per_class(preds,labels):\n",
        "  label_dict_invers={v:k for k ,v in label_dict.items()}\n",
        "\n",
        "  preds_flat=np.argmax(preds,axis=1).flatten()\n",
        "  labels_flat=labels.flatten()\n",
        "\n",
        "  for label in np.unique(labels_flat):\n",
        "    y_preds=preds_flat[labels_flat==label]\n",
        "    y_true=labels_flat[labels_flat==label]\n",
        "    print(f'Class:{label_dict_invers[label]}')\n",
        "    print(f'Accuracy:{len(y_preds[y_preds==label])}/{len(y_true)}\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvvoKHzMJvCW"
      },
      "source": [
        "import random\n",
        "\n",
        "seed_val=17\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHkjtlq5JvJf",
        "outputId": "a5261994-c22e-4a6f-a7bd-8f46581540fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "print('Device: {}'.format(device))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device: cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EK1RYX6TJvZv"
      },
      "source": [
        "def evaluate(dataloader_val):\n",
        "  model.eval()\n",
        "\n",
        "  loss_val_total=0\n",
        "  predictions,true_vals=[],[]\n",
        "\n",
        "  for batch in dataloader_val:\n",
        "    batch=tupel(b.to(device)for b in batch)\n",
        "\n",
        "    inputs={'input_ids': batch[0],\n",
        "            'attention_mask':batch[1],\n",
        "            'labels': batch[2],\n",
        "    }\n",
        "\n",
        "    with torch.no_grad():\n",
        "      output=model(**inputs)\n",
        "\n",
        "    loss=outputs[0]\n",
        "    logits=output[1]\n",
        "    loss_val_total+=loss.item()\n",
        "\n",
        "    logits=logits.detach().cpu().numpy()\n",
        "    label_ids=input['labels'].cpu().numpy()\n",
        "    predictions.append(logits)\n",
        "    true_vals.append(label_ids)\n",
        "\n",
        "  loss_val_avg=loss_val_total/len(dataloader_val)\n",
        "\n",
        "  predictions=np.concatenate(predictions,axis=0)\n",
        "  true_vals=np.concatenate(true_vals,axis=0)\n",
        "\n",
        "  return loss_val_avg,predictions,true_vals\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4SZe2X3cGgV"
      },
      "source": [
        "#Evaluation, Accuracy etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NZoVRXFSzg2",
        "outputId": "ec9853b5-40ea-443a-f7d1-ea89b6261962",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tqdm import tqdm\n",
        "for epoch in tqdm(range(1,epochs+1)):\n",
        "  model.train()\n",
        "  loss_train_total=0\n",
        "  progress_bar=tqdm(dataloader_train, desc='Epoch{:1d}'.format(epoch), leave=False, disable=False)\n",
        "  for batch in progress_bar:\n",
        "    model.zero_grad()\n",
        "    batch=tuple(b.to(device) for b in batch)\n",
        "\n",
        "    inputs={\n",
        "        'input_ids' :batch[0],\n",
        "        'attention_mask':batch[1],\n",
        "        'labels' : batch[2]\n",
        "    }\n",
        "\n",
        "    outputs=model(**inputs)\n",
        "    loss=outputs[0]\n",
        "    loss_train_total+=loss.item()\n",
        "    loss.backward()\n",
        "\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(),1.0)\n",
        "\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "\n",
        "    progress_bar.set_postfix({'training_loss':'{:.3f}'.format(loss.item()/len(batch)    )})\n",
        "\n",
        "  torch.save(model.state_dict(),f'Models/BERT_ft_epoch{epoch}.model')\n",
        "  tdqm.write('\\nEpoch {epoch}')\n",
        "\n",
        "  loss_train_avg=loss_train_total/len(dataloader)\n",
        "  tqdm.write(f'Traning loss:{loss_train_avg}')\n",
        "\n",
        "  val_loss,predictions,true_vals=evaluate(dataloader_val)\n",
        "  val_f1=f1_score_func(predictions,true_vals)\n",
        "  tqdm.write(f'Validation loss :{val_loss}')\n",
        "  tqdm.write(f'F1 Score (weighted):{val_f1}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/10 [00:00<?, ?it/s]\n",
            "Epoch1:   0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch1:   0%|          | 0/40 [00:01<?, ?it/s, training_loss=0.749]\u001b[A\n",
            "Epoch1:   2%|â–Ž         | 1/40 [00:01<01:04,  1.64s/it, training_loss=0.749]\u001b[A\n",
            "Epoch1:   2%|â–Ž         | 1/40 [00:02<01:04,  1.64s/it, training_loss=0.684]\u001b[A\n",
            "Epoch1:   5%|â–Œ         | 2/40 [00:02<00:58,  1.53s/it, training_loss=0.684]\u001b[A\n",
            "Epoch1:   5%|â–Œ         | 2/40 [00:04<00:58,  1.53s/it, training_loss=0.614]\u001b[A\n",
            "Epoch1:   8%|â–Š         | 3/40 [00:04<00:53,  1.46s/it, training_loss=0.614]\u001b[A\n",
            "Epoch1:   8%|â–Š         | 3/40 [00:05<00:53,  1.46s/it, training_loss=0.558]\u001b[A\n",
            "Epoch1:  10%|â–ˆ         | 4/40 [00:05<00:50,  1.41s/it, training_loss=0.558]\u001b[A\n",
            "Epoch1:  10%|â–ˆ         | 4/40 [00:06<00:50,  1.41s/it, training_loss=0.499]\u001b[A\n",
            "Epoch1:  12%|â–ˆâ–Ž        | 5/40 [00:06<00:48,  1.37s/it, training_loss=0.499]\u001b[A\n",
            "Epoch1:  12%|â–ˆâ–Ž        | 5/40 [00:08<00:48,  1.37s/it, training_loss=0.497]\u001b[A\n",
            "Epoch1:  15%|â–ˆâ–Œ        | 6/40 [00:08<00:45,  1.35s/it, training_loss=0.497]\u001b[A\n",
            "Epoch1:  15%|â–ˆâ–Œ        | 6/40 [00:09<00:45,  1.35s/it, training_loss=0.479]\u001b[A\n",
            "Epoch1:  18%|â–ˆâ–Š        | 7/40 [00:09<00:44,  1.34s/it, training_loss=0.479]\u001b[A\n",
            "Epoch1:  18%|â–ˆâ–Š        | 7/40 [00:10<00:44,  1.34s/it, training_loss=0.494]\u001b[A\n",
            "Epoch1:  20%|â–ˆâ–ˆ        | 8/40 [00:10<00:42,  1.33s/it, training_loss=0.494]\u001b[A\n",
            "Epoch1:  20%|â–ˆâ–ˆ        | 8/40 [00:11<00:42,  1.33s/it, training_loss=0.465]\u001b[A\n",
            "Epoch1:  22%|â–ˆâ–ˆâ–Ž       | 9/40 [00:12<00:40,  1.32s/it, training_loss=0.465]\u001b[A\n",
            "Epoch1:  22%|â–ˆâ–ˆâ–Ž       | 9/40 [00:13<00:40,  1.32s/it, training_loss=0.473]\u001b[A\n",
            "Epoch1:  25%|â–ˆâ–ˆâ–Œ       | 10/40 [00:13<00:39,  1.32s/it, training_loss=0.473]\u001b[A\n",
            "Epoch1:  25%|â–ˆâ–ˆâ–Œ       | 10/40 [00:14<00:39,  1.32s/it, training_loss=0.449]\u001b[A\n",
            "Epoch1:  28%|â–ˆâ–ˆâ–Š       | 11/40 [00:14<00:38,  1.31s/it, training_loss=0.449]\u001b[A\n",
            "Epoch1:  28%|â–ˆâ–ˆâ–Š       | 11/40 [00:15<00:38,  1.31s/it, training_loss=0.475]\u001b[A\n",
            "Epoch1:  30%|â–ˆâ–ˆâ–ˆ       | 12/40 [00:15<00:36,  1.31s/it, training_loss=0.475]\u001b[A\n",
            "Epoch1:  30%|â–ˆâ–ˆâ–ˆ       | 12/40 [00:17<00:36,  1.31s/it, training_loss=0.448]\u001b[A\n",
            "Epoch1:  32%|â–ˆâ–ˆâ–ˆâ–Ž      | 13/40 [00:17<00:35,  1.31s/it, training_loss=0.448]\u001b[A\n",
            "Epoch1:  32%|â–ˆâ–ˆâ–ˆâ–Ž      | 13/40 [00:18<00:35,  1.31s/it, training_loss=0.440]\u001b[A\n",
            "Epoch1:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 14/40 [00:18<00:34,  1.32s/it, training_loss=0.440]\u001b[A\n",
            "Epoch1:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 14/40 [00:19<00:34,  1.32s/it, training_loss=0.426]\u001b[A\n",
            "Epoch1:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 15/40 [00:19<00:32,  1.32s/it, training_loss=0.426]\u001b[A\n",
            "Epoch1:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 15/40 [00:21<00:32,  1.32s/it, training_loss=0.426]\u001b[A\n",
            "Epoch1:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 16/40 [00:21<00:31,  1.32s/it, training_loss=0.426]\u001b[A\n",
            "Epoch1:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 16/40 [00:22<00:31,  1.32s/it, training_loss=0.417]\u001b[A\n",
            "Epoch1:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 17/40 [00:22<00:30,  1.32s/it, training_loss=0.417]\u001b[A\n",
            "Epoch1:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 17/40 [00:23<00:30,  1.32s/it, training_loss=0.426]\u001b[A\n",
            "Epoch1:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 18/40 [00:23<00:29,  1.32s/it, training_loss=0.426]\u001b[A\n",
            "Epoch1:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 18/40 [00:25<00:29,  1.32s/it, training_loss=0.352]\u001b[A\n",
            "Epoch1:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 19/40 [00:25<00:27,  1.32s/it, training_loss=0.352]\u001b[A\n",
            "Epoch1:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 19/40 [00:26<00:27,  1.32s/it, training_loss=0.378]\u001b[A\n",
            "Epoch1:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 20/40 [00:26<00:26,  1.32s/it, training_loss=0.378]\u001b[A\n",
            "Epoch1:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 20/40 [00:27<00:26,  1.32s/it, training_loss=0.381]\u001b[A\n",
            "Epoch1:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 21/40 [00:27<00:25,  1.32s/it, training_loss=0.381]\u001b[A\n",
            "Epoch1:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 21/40 [00:29<00:25,  1.32s/it, training_loss=0.379]\u001b[A\n",
            "Epoch1:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 22/40 [00:29<00:23,  1.33s/it, training_loss=0.379]\u001b[A\n",
            "Epoch1:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 22/40 [00:30<00:23,  1.33s/it, training_loss=0.404]\u001b[A\n",
            "Epoch1:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 23/40 [00:30<00:22,  1.33s/it, training_loss=0.404]\u001b[A\n",
            "Epoch1:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 23/40 [00:31<00:22,  1.33s/it, training_loss=0.421]\u001b[A\n",
            "Epoch1:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 24/40 [00:31<00:21,  1.33s/it, training_loss=0.421]\u001b[A\n",
            "Epoch1:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 24/40 [00:33<00:21,  1.33s/it, training_loss=0.399]\u001b[A\n",
            "Epoch1:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 25/40 [00:33<00:20,  1.34s/it, training_loss=0.399]\u001b[A\n",
            "Epoch1:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 25/40 [00:34<00:20,  1.34s/it, training_loss=0.327]\u001b[A\n",
            "Epoch1:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 26/40 [00:34<00:18,  1.34s/it, training_loss=0.327]\u001b[A\n",
            "Epoch1:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 26/40 [00:35<00:18,  1.34s/it, training_loss=0.367]\u001b[A\n",
            "Epoch1:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 27/40 [00:35<00:17,  1.34s/it, training_loss=0.367]\u001b[A\n",
            "Epoch1:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 27/40 [00:37<00:17,  1.34s/it, training_loss=0.315]\u001b[A\n",
            "Epoch1:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 28/40 [00:37<00:16,  1.35s/it, training_loss=0.315]\u001b[A\n",
            "Epoch1:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 28/40 [00:38<00:16,  1.35s/it, training_loss=0.357]\u001b[A\n",
            "Epoch1:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 29/40 [00:38<00:14,  1.35s/it, training_loss=0.357]\u001b[A\n",
            "Epoch1:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 29/40 [00:39<00:14,  1.35s/it, training_loss=0.260]\u001b[A\n",
            "Epoch1:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 30/40 [00:39<00:13,  1.36s/it, training_loss=0.260]\u001b[A\n",
            "Epoch1:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 30/40 [00:41<00:13,  1.36s/it, training_loss=0.260]\u001b[A\n",
            "Epoch1:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 31/40 [00:41<00:12,  1.36s/it, training_loss=0.260]\u001b[A\n",
            "Epoch1:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 31/40 [00:42<00:12,  1.36s/it, training_loss=0.267]\u001b[A\n",
            "Epoch1:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 32/40 [00:42<00:10,  1.36s/it, training_loss=0.267]\u001b[A\n",
            "Epoch1:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 32/40 [00:44<00:10,  1.36s/it, training_loss=0.333]\u001b[A\n",
            "Epoch1:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 33/40 [00:44<00:09,  1.36s/it, training_loss=0.333]\u001b[A\n",
            "Epoch1:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 33/40 [00:45<00:09,  1.36s/it, training_loss=0.360]\u001b[A\n",
            "Epoch1:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 34/40 [00:45<00:08,  1.37s/it, training_loss=0.360]\u001b[A\n",
            "Epoch1:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 34/40 [00:46<00:08,  1.37s/it, training_loss=0.315]\u001b[A\n",
            "Epoch1:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 35/40 [00:46<00:06,  1.37s/it, training_loss=0.315]\u001b[A\n",
            "Epoch1:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 35/40 [00:48<00:06,  1.37s/it, training_loss=0.388]\u001b[A\n",
            "Epoch1:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 36/40 [00:48<00:05,  1.38s/it, training_loss=0.388]\u001b[A\n",
            "Epoch1:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 36/40 [00:49<00:05,  1.38s/it, training_loss=0.231]\u001b[A\n",
            "Epoch1:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 37/40 [00:49<00:04,  1.38s/it, training_loss=0.231]\u001b[A\n",
            "Epoch1:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 37/40 [00:50<00:04,  1.38s/it, training_loss=0.213]\u001b[A\n",
            "Epoch1:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 38/40 [00:51<00:02,  1.38s/it, training_loss=0.213]\u001b[A\n",
            "Epoch1:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 38/40 [00:52<00:02,  1.38s/it, training_loss=0.312]\u001b[A\n",
            "Epoch1:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 39/40 [00:52<00:01,  1.39s/it, training_loss=0.312]\u001b[A\n",
            "Epoch1:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 39/40 [00:52<00:01,  1.39s/it, training_loss=0.255]\u001b[A\n",
            "Epoch1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:52<00:00,  1.12s/it, training_loss=0.255]\u001b[A\n",
            " 10%|â–ˆ         | 1/10 [00:52<07:56, 52.89s/it]\n",
            "Epoch2:   0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch2:   0%|          | 0/40 [00:01<?, ?it/s, training_loss=0.277]\u001b[A\n",
            "Epoch2:   2%|â–Ž         | 1/40 [00:01<00:54,  1.39s/it, training_loss=0.277]\u001b[A\n",
            "Epoch2:   2%|â–Ž         | 1/40 [00:02<00:54,  1.39s/it, training_loss=0.293]\u001b[A\n",
            "Epoch2:   5%|â–Œ         | 2/40 [00:02<00:53,  1.40s/it, training_loss=0.293]\u001b[A\n",
            "Epoch2:   5%|â–Œ         | 2/40 [00:04<00:53,  1.40s/it, training_loss=0.167]\u001b[A\n",
            "Epoch2:   8%|â–Š         | 3/40 [00:04<00:51,  1.40s/it, training_loss=0.167]\u001b[A\n",
            "Epoch2:   8%|â–Š         | 3/40 [00:05<00:51,  1.40s/it, training_loss=0.279]\u001b[A\n",
            "Epoch2:  10%|â–ˆ         | 4/40 [00:05<00:50,  1.40s/it, training_loss=0.279]\u001b[A\n",
            "Epoch2:  10%|â–ˆ         | 4/40 [00:07<00:50,  1.40s/it, training_loss=0.277]\u001b[A\n",
            "Epoch2:  12%|â–ˆâ–Ž        | 5/40 [00:07<00:49,  1.40s/it, training_loss=0.277]\u001b[A\n",
            "Epoch2:  12%|â–ˆâ–Ž        | 5/40 [00:08<00:49,  1.40s/it, training_loss=0.239]\u001b[A\n",
            "Epoch2:  15%|â–ˆâ–Œ        | 6/40 [00:08<00:47,  1.40s/it, training_loss=0.239]\u001b[A\n",
            "Epoch2:  15%|â–ˆâ–Œ        | 6/40 [00:09<00:47,  1.40s/it, training_loss=0.241]\u001b[A\n",
            "Epoch2:  18%|â–ˆâ–Š        | 7/40 [00:09<00:46,  1.41s/it, training_loss=0.241]\u001b[A\n",
            "Epoch2:  18%|â–ˆâ–Š        | 7/40 [00:11<00:46,  1.41s/it, training_loss=0.198]\u001b[A\n",
            "Epoch2:  20%|â–ˆâ–ˆ        | 8/40 [00:11<00:45,  1.41s/it, training_loss=0.198]\u001b[A\n",
            "Epoch2:  20%|â–ˆâ–ˆ        | 8/40 [00:12<00:45,  1.41s/it, training_loss=0.330]\u001b[A\n",
            "Epoch2:  22%|â–ˆâ–ˆâ–Ž       | 9/40 [00:12<00:43,  1.41s/it, training_loss=0.330]\u001b[A\n",
            "Epoch2:  22%|â–ˆâ–ˆâ–Ž       | 9/40 [00:14<00:43,  1.41s/it, training_loss=0.176]\u001b[A\n",
            "Epoch2:  25%|â–ˆâ–ˆâ–Œ       | 10/40 [00:14<00:42,  1.42s/it, training_loss=0.176]\u001b[A\n",
            "Epoch2:  25%|â–ˆâ–ˆâ–Œ       | 10/40 [00:15<00:42,  1.42s/it, training_loss=0.248]\u001b[A\n",
            "Epoch2:  28%|â–ˆâ–ˆâ–Š       | 11/40 [00:15<00:41,  1.42s/it, training_loss=0.248]\u001b[A\n",
            "Epoch2:  28%|â–ˆâ–ˆâ–Š       | 11/40 [00:16<00:41,  1.42s/it, training_loss=0.203]\u001b[A\n",
            "Epoch2:  30%|â–ˆâ–ˆâ–ˆ       | 12/40 [00:16<00:39,  1.42s/it, training_loss=0.203]\u001b[A\n",
            "Epoch2:  30%|â–ˆâ–ˆâ–ˆ       | 12/40 [00:18<00:39,  1.42s/it, training_loss=0.314]\u001b[A\n",
            "Epoch2:  32%|â–ˆâ–ˆâ–ˆâ–Ž      | 13/40 [00:18<00:38,  1.43s/it, training_loss=0.314]\u001b[A\n",
            "Epoch2:  32%|â–ˆâ–ˆâ–ˆâ–Ž      | 13/40 [00:19<00:38,  1.43s/it, training_loss=0.242]\u001b[A\n",
            "Epoch2:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 14/40 [00:19<00:37,  1.43s/it, training_loss=0.242]\u001b[A\n",
            "Epoch2:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 14/40 [00:21<00:37,  1.43s/it, training_loss=0.220]\u001b[A\n",
            "Epoch2:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 15/40 [00:21<00:35,  1.44s/it, training_loss=0.220]\u001b[A\n",
            "Epoch2:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 15/40 [00:22<00:35,  1.44s/it, training_loss=0.195]\u001b[A\n",
            "Epoch2:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 16/40 [00:22<00:34,  1.44s/it, training_loss=0.195]\u001b[A\n",
            "Epoch2:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 16/40 [00:24<00:34,  1.44s/it, training_loss=0.281]\u001b[A\n",
            "Epoch2:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 17/40 [00:24<00:33,  1.45s/it, training_loss=0.281]\u001b[A\n",
            "Epoch2:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 17/40 [00:25<00:33,  1.45s/it, training_loss=0.166]\u001b[A\n",
            "Epoch2:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 18/40 [00:25<00:31,  1.45s/it, training_loss=0.166]\u001b[A\n",
            "Epoch2:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 18/40 [00:27<00:31,  1.45s/it, training_loss=0.296]\u001b[A\n",
            "Epoch2:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 19/40 [00:27<00:30,  1.45s/it, training_loss=0.296]\u001b[A\n",
            "Epoch2:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 19/40 [00:28<00:30,  1.45s/it, training_loss=0.270]\u001b[A\n",
            "Epoch2:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 20/40 [00:28<00:29,  1.46s/it, training_loss=0.270]\u001b[A\n",
            "Epoch2:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 20/40 [00:30<00:29,  1.46s/it, training_loss=0.320]\u001b[A\n",
            "Epoch2:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 21/40 [00:30<00:27,  1.46s/it, training_loss=0.320]\u001b[A\n",
            "Epoch2:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 21/40 [00:31<00:27,  1.46s/it, training_loss=0.197]\u001b[A\n",
            "Epoch2:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 22/40 [00:31<00:26,  1.46s/it, training_loss=0.197]\u001b[A\n",
            "Epoch2:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 22/40 [00:32<00:26,  1.46s/it, training_loss=0.269]\u001b[A\n",
            "Epoch2:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 23/40 [00:32<00:24,  1.47s/it, training_loss=0.269]\u001b[A\n",
            "Epoch2:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 23/40 [00:34<00:24,  1.47s/it, training_loss=0.257]\u001b[A\n",
            "Epoch2:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 24/40 [00:34<00:23,  1.47s/it, training_loss=0.257]\u001b[A\n",
            "Epoch2:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 24/40 [00:35<00:23,  1.47s/it, training_loss=0.228]\u001b[A\n",
            "Epoch2:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 25/40 [00:35<00:22,  1.47s/it, training_loss=0.228]\u001b[A\n",
            "Epoch2:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 25/40 [00:37<00:22,  1.47s/it, training_loss=0.277]\u001b[A\n",
            "Epoch2:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 26/40 [00:37<00:20,  1.48s/it, training_loss=0.277]\u001b[A\n",
            "Epoch2:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 26/40 [00:38<00:20,  1.48s/it, training_loss=0.266]\u001b[A\n",
            "Epoch2:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 27/40 [00:38<00:19,  1.48s/it, training_loss=0.266]\u001b[A\n",
            "Epoch2:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 27/40 [00:40<00:19,  1.48s/it, training_loss=0.176]\u001b[A\n",
            "Epoch2:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 28/40 [00:40<00:17,  1.48s/it, training_loss=0.176]\u001b[A\n",
            "Epoch2:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 28/40 [00:41<00:17,  1.48s/it, training_loss=0.293]\u001b[A\n",
            "Epoch2:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 29/40 [00:41<00:16,  1.48s/it, training_loss=0.293]\u001b[A\n",
            "Epoch2:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 29/40 [00:43<00:16,  1.48s/it, training_loss=0.337]\u001b[A\n",
            "Epoch2:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 30/40 [00:43<00:14,  1.49s/it, training_loss=0.337]\u001b[A\n",
            "Epoch2:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 30/40 [00:44<00:14,  1.49s/it, training_loss=0.246]\u001b[A\n",
            "Epoch2:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 31/40 [00:44<00:13,  1.49s/it, training_loss=0.246]\u001b[A\n",
            "Epoch2:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 31/40 [00:46<00:13,  1.49s/it, training_loss=0.173]\u001b[A\n",
            "Epoch2:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 32/40 [00:46<00:11,  1.49s/it, training_loss=0.173]\u001b[A\n",
            "Epoch2:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 32/40 [00:47<00:11,  1.49s/it, training_loss=0.249]\u001b[A\n",
            "Epoch2:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 33/40 [00:47<00:10,  1.50s/it, training_loss=0.249]\u001b[A\n",
            "Epoch2:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 33/40 [00:49<00:10,  1.50s/it, training_loss=0.220]\u001b[A\n",
            "Epoch2:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 34/40 [00:49<00:08,  1.50s/it, training_loss=0.220]\u001b[A\n",
            "Epoch2:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 34/40 [00:50<00:08,  1.50s/it, training_loss=0.308]\u001b[A\n",
            "Epoch2:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 35/40 [00:50<00:07,  1.50s/it, training_loss=0.308]\u001b[A\n",
            "Epoch2:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 35/40 [00:52<00:07,  1.50s/it, training_loss=0.103]\u001b[A\n",
            "Epoch2:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 36/40 [00:52<00:05,  1.49s/it, training_loss=0.103]\u001b[A\n",
            "Epoch2:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 36/40 [00:53<00:05,  1.49s/it, training_loss=0.173]\u001b[A\n",
            "Epoch2:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 37/40 [00:53<00:04,  1.49s/it, training_loss=0.173]\u001b[A\n",
            "Epoch2:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 37/40 [00:55<00:04,  1.49s/it, training_loss=0.252]\u001b[A\n",
            "Epoch2:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 38/40 [00:55<00:02,  1.49s/it, training_loss=0.252]\u001b[A\n",
            "Epoch2:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 38/40 [00:56<00:02,  1.49s/it, training_loss=0.173]\u001b[A\n",
            "Epoch2:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 39/40 [00:56<00:01,  1.49s/it, training_loss=0.173]\u001b[A\n",
            "Epoch2:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 39/40 [00:57<00:01,  1.49s/it, training_loss=0.223]\u001b[A\n",
            "Epoch2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:57<00:00,  1.20s/it, training_loss=0.223]\u001b[A\n",
            " 20%|â–ˆâ–ˆ        | 2/10 [01:50<07:13, 54.23s/it]\n",
            "Epoch3:   0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch3:   0%|          | 0/40 [00:01<?, ?it/s, training_loss=0.214]\u001b[A\n",
            "Epoch3:   2%|â–Ž         | 1/40 [00:01<00:57,  1.48s/it, training_loss=0.214]\u001b[A\n",
            "Epoch3:   2%|â–Ž         | 1/40 [00:02<00:57,  1.48s/it, training_loss=0.138]\u001b[A\n",
            "Epoch3:   5%|â–Œ         | 2/40 [00:02<00:56,  1.48s/it, training_loss=0.138]\u001b[A\n",
            "Epoch3:   5%|â–Œ         | 2/40 [00:04<00:56,  1.48s/it, training_loss=0.146]\u001b[A\n",
            "Epoch3:   8%|â–Š         | 3/40 [00:04<00:54,  1.48s/it, training_loss=0.146]\u001b[A\n",
            "Epoch3:   8%|â–Š         | 3/40 [00:05<00:54,  1.48s/it, training_loss=0.226]\u001b[A\n",
            "Epoch3:  10%|â–ˆ         | 4/40 [00:05<00:53,  1.48s/it, training_loss=0.226]\u001b[A\n",
            "Epoch3:  10%|â–ˆ         | 4/40 [00:07<00:53,  1.48s/it, training_loss=0.113]\u001b[A\n",
            "Epoch3:  12%|â–ˆâ–Ž        | 5/40 [00:07<00:51,  1.47s/it, training_loss=0.113]\u001b[A\n",
            "Epoch3:  12%|â–ˆâ–Ž        | 5/40 [00:08<00:51,  1.47s/it, training_loss=0.222]\u001b[A\n",
            "Epoch3:  15%|â–ˆâ–Œ        | 6/40 [00:08<00:49,  1.47s/it, training_loss=0.222]\u001b[A\n",
            "Epoch3:  15%|â–ˆâ–Œ        | 6/40 [00:10<00:49,  1.47s/it, training_loss=0.132]\u001b[A\n",
            "Epoch3:  18%|â–ˆâ–Š        | 7/40 [00:10<00:48,  1.47s/it, training_loss=0.132]\u001b[A\n",
            "Epoch3:  18%|â–ˆâ–Š        | 7/40 [00:11<00:48,  1.47s/it, training_loss=0.201]\u001b[A\n",
            "Epoch3:  20%|â–ˆâ–ˆ        | 8/40 [00:11<00:46,  1.46s/it, training_loss=0.201]\u001b[A\n",
            "Epoch3:  20%|â–ˆâ–ˆ        | 8/40 [00:13<00:46,  1.46s/it, training_loss=0.171]\u001b[A\n",
            "Epoch3:  22%|â–ˆâ–ˆâ–Ž       | 9/40 [00:13<00:45,  1.46s/it, training_loss=0.171]\u001b[A\n",
            "Epoch3:  22%|â–ˆâ–ˆâ–Ž       | 9/40 [00:14<00:45,  1.46s/it, training_loss=0.228]\u001b[A\n",
            "Epoch3:  25%|â–ˆâ–ˆâ–Œ       | 10/40 [00:14<00:43,  1.46s/it, training_loss=0.228]\u001b[A\n",
            "Epoch3:  25%|â–ˆâ–ˆâ–Œ       | 10/40 [00:16<00:43,  1.46s/it, training_loss=0.233]\u001b[A\n",
            "Epoch3:  28%|â–ˆâ–ˆâ–Š       | 11/40 [00:16<00:42,  1.46s/it, training_loss=0.233]\u001b[A\n",
            "Epoch3:  28%|â–ˆâ–ˆâ–Š       | 11/40 [00:17<00:42,  1.46s/it, training_loss=0.207]\u001b[A\n",
            "Epoch3:  30%|â–ˆâ–ˆâ–ˆ       | 12/40 [00:17<00:40,  1.46s/it, training_loss=0.207]\u001b[A\n",
            "Epoch3:  30%|â–ˆâ–ˆâ–ˆ       | 12/40 [00:19<00:40,  1.46s/it, training_loss=0.275]\u001b[A\n",
            "Epoch3:  32%|â–ˆâ–ˆâ–ˆâ–Ž      | 13/40 [00:19<00:39,  1.46s/it, training_loss=0.275]\u001b[A\n",
            "Epoch3:  32%|â–ˆâ–ˆâ–ˆâ–Ž      | 13/40 [00:20<00:39,  1.46s/it, training_loss=0.215]\u001b[A\n",
            "Epoch3:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 14/40 [00:20<00:37,  1.45s/it, training_loss=0.215]\u001b[A\n",
            "Epoch3:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 14/40 [00:21<00:37,  1.45s/it, training_loss=0.208]\u001b[A\n",
            "Epoch3:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 15/40 [00:21<00:36,  1.45s/it, training_loss=0.208]\u001b[A\n",
            "Epoch3:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 15/40 [00:23<00:36,  1.45s/it, training_loss=0.211]\u001b[A\n",
            "Epoch3:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 16/40 [00:23<00:34,  1.45s/it, training_loss=0.211]\u001b[A\n",
            "Epoch3:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 16/40 [00:24<00:34,  1.45s/it, training_loss=0.256]\u001b[A\n",
            "Epoch3:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 17/40 [00:24<00:33,  1.45s/it, training_loss=0.256]\u001b[A\n",
            "Epoch3:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 17/40 [00:26<00:33,  1.45s/it, training_loss=0.164]\u001b[A\n",
            "Epoch3:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 18/40 [00:26<00:31,  1.45s/it, training_loss=0.164]\u001b[A\n",
            "Epoch3:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 18/40 [00:27<00:31,  1.45s/it, training_loss=0.233]\u001b[A\n",
            "Epoch3:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 19/40 [00:27<00:30,  1.45s/it, training_loss=0.233]\u001b[A\n",
            "Epoch3:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 19/40 [00:29<00:30,  1.45s/it, training_loss=0.174]\u001b[A\n",
            "Epoch3:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 20/40 [00:29<00:29,  1.45s/it, training_loss=0.174]\u001b[A\n",
            "Epoch3:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 20/40 [00:30<00:29,  1.45s/it, training_loss=0.152]\u001b[A\n",
            "Epoch3:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 21/40 [00:30<00:27,  1.45s/it, training_loss=0.152]\u001b[A\n",
            "Epoch3:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 21/40 [00:32<00:27,  1.45s/it, training_loss=0.222]\u001b[A\n",
            "Epoch3:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 22/40 [00:32<00:26,  1.45s/it, training_loss=0.222]\u001b[A\n",
            "Epoch3:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 22/40 [00:33<00:26,  1.45s/it, training_loss=0.144]\u001b[A\n",
            "Epoch3:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 23/40 [00:33<00:24,  1.45s/it, training_loss=0.144]\u001b[A\n",
            "Epoch3:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 23/40 [00:35<00:24,  1.45s/it, training_loss=0.196]\u001b[A\n",
            "Epoch3:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 24/40 [00:35<00:23,  1.46s/it, training_loss=0.196]\u001b[A\n",
            "Epoch3:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 24/40 [00:36<00:23,  1.46s/it, training_loss=0.118]\u001b[A\n",
            "Epoch3:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 25/40 [00:36<00:21,  1.45s/it, training_loss=0.118]\u001b[A\n",
            "Epoch3:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 25/40 [00:37<00:21,  1.45s/it, training_loss=0.182]\u001b[A\n",
            "Epoch3:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 26/40 [00:37<00:20,  1.45s/it, training_loss=0.182]\u001b[A\n",
            "Epoch3:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 26/40 [00:39<00:20,  1.45s/it, training_loss=0.231]\u001b[A\n",
            "Epoch3:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 27/40 [00:39<00:18,  1.45s/it, training_loss=0.231]\u001b[A\n",
            "Epoch3:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 27/40 [00:40<00:18,  1.45s/it, training_loss=0.172]\u001b[A\n",
            "Epoch3:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 28/40 [00:40<00:17,  1.46s/it, training_loss=0.172]\u001b[A\n",
            "Epoch3:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 28/40 [00:42<00:17,  1.46s/it, training_loss=0.165]\u001b[A\n",
            "Epoch3:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 29/40 [00:42<00:15,  1.45s/it, training_loss=0.165]\u001b[A\n",
            "Epoch3:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 29/40 [00:43<00:15,  1.45s/it, training_loss=0.175]\u001b[A\n",
            "Epoch3:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 30/40 [00:43<00:14,  1.45s/it, training_loss=0.175]\u001b[A\n",
            "Epoch3:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 30/40 [00:45<00:14,  1.45s/it, training_loss=0.153]\u001b[A\n",
            "Epoch3:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 31/40 [00:45<00:13,  1.46s/it, training_loss=0.153]\u001b[A\n",
            "Epoch3:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 31/40 [00:46<00:13,  1.46s/it, training_loss=0.207]\u001b[A\n",
            "Epoch3:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 32/40 [00:46<00:11,  1.46s/it, training_loss=0.207]\u001b[A\n",
            "Epoch3:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 32/40 [00:48<00:11,  1.46s/it, training_loss=0.129]\u001b[A\n",
            "Epoch3:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 33/40 [00:48<00:10,  1.46s/it, training_loss=0.129]\u001b[A\n",
            "Epoch3:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 33/40 [00:49<00:10,  1.46s/it, training_loss=0.248]\u001b[A\n",
            "Epoch3:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 34/40 [00:49<00:08,  1.46s/it, training_loss=0.248]\u001b[A\n",
            "Epoch3:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 34/40 [00:51<00:08,  1.46s/it, training_loss=0.139]\u001b[A\n",
            "Epoch3:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 35/40 [00:51<00:07,  1.46s/it, training_loss=0.139]\u001b[A\n",
            "Epoch3:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 35/40 [00:52<00:07,  1.46s/it, training_loss=0.190]\u001b[A\n",
            "Epoch3:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 36/40 [00:52<00:05,  1.46s/it, training_loss=0.190]\u001b[A\n",
            "Epoch3:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 36/40 [00:53<00:05,  1.46s/it, training_loss=0.203]\u001b[A\n",
            "Epoch3:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 37/40 [00:53<00:04,  1.46s/it, training_loss=0.203]\u001b[A\n",
            "Epoch3:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 37/40 [00:55<00:04,  1.46s/it, training_loss=0.204]\u001b[A\n",
            "Epoch3:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 38/40 [00:55<00:02,  1.46s/it, training_loss=0.204]\u001b[A\n",
            "Epoch3:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 38/40 [00:56<00:02,  1.46s/it, training_loss=0.187]\u001b[A\n",
            "Epoch3:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 39/40 [00:56<00:01,  1.46s/it, training_loss=0.187]\u001b[A\n",
            "Epoch3:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 39/40 [00:57<00:01,  1.46s/it, training_loss=0.183]\u001b[A\n",
            "Epoch3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:57<00:00,  1.18s/it, training_loss=0.183]\u001b[A\n",
            " 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [02:47<06:26, 55.19s/it]\n",
            "Epoch4:   0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch4:   0%|          | 0/40 [00:01<?, ?it/s, training_loss=0.162]\u001b[A\n",
            "Epoch4:   2%|â–Ž         | 1/40 [00:01<00:56,  1.46s/it, training_loss=0.162]\u001b[A\n",
            "Epoch4:   2%|â–Ž         | 1/40 [00:02<00:56,  1.46s/it, training_loss=0.150]\u001b[A\n",
            "Epoch4:   5%|â–Œ         | 2/40 [00:02<00:55,  1.46s/it, training_loss=0.150]\u001b[A\n",
            "Epoch4:   5%|â–Œ         | 2/40 [00:04<00:55,  1.46s/it, training_loss=0.123]\u001b[A\n",
            "Epoch4:   8%|â–Š         | 3/40 [00:04<00:54,  1.47s/it, training_loss=0.123]\u001b[A\n",
            "Epoch4:   8%|â–Š         | 3/40 [00:05<00:54,  1.47s/it, training_loss=0.197]\u001b[A\n",
            "Epoch4:  10%|â–ˆ         | 4/40 [00:05<00:52,  1.47s/it, training_loss=0.197]\u001b[A\n",
            "Epoch4:  10%|â–ˆ         | 4/40 [00:07<00:52,  1.47s/it, training_loss=0.263]\u001b[A\n",
            "Epoch4:  12%|â–ˆâ–Ž        | 5/40 [00:07<00:51,  1.47s/it, training_loss=0.263]\u001b[A\n",
            "Epoch4:  12%|â–ˆâ–Ž        | 5/40 [00:08<00:51,  1.47s/it, training_loss=0.130]\u001b[A\n",
            "Epoch4:  15%|â–ˆâ–Œ        | 6/40 [00:08<00:49,  1.47s/it, training_loss=0.130]\u001b[A\n",
            "Epoch4:  15%|â–ˆâ–Œ        | 6/40 [00:10<00:49,  1.47s/it, training_loss=0.183]\u001b[A\n",
            "Epoch4:  18%|â–ˆâ–Š        | 7/40 [00:10<00:48,  1.47s/it, training_loss=0.183]\u001b[A\n",
            "Epoch4:  18%|â–ˆâ–Š        | 7/40 [00:11<00:48,  1.47s/it, training_loss=0.203]\u001b[A\n",
            "Epoch4:  20%|â–ˆâ–ˆ        | 8/40 [00:11<00:47,  1.47s/it, training_loss=0.203]\u001b[A\n",
            "Epoch4:  20%|â–ˆâ–ˆ        | 8/40 [00:13<00:47,  1.47s/it, training_loss=0.139]\u001b[A\n",
            "Epoch4:  22%|â–ˆâ–ˆâ–Ž       | 9/40 [00:13<00:45,  1.47s/it, training_loss=0.139]\u001b[A\n",
            "Epoch4:  22%|â–ˆâ–ˆâ–Ž       | 9/40 [00:14<00:45,  1.47s/it, training_loss=0.197]\u001b[A\n",
            "Epoch4:  25%|â–ˆâ–ˆâ–Œ       | 10/40 [00:14<00:44,  1.47s/it, training_loss=0.197]\u001b[A\n",
            "Epoch4:  25%|â–ˆâ–ˆâ–Œ       | 10/40 [00:16<00:44,  1.47s/it, training_loss=0.201]\u001b[A\n",
            "Epoch4:  28%|â–ˆâ–ˆâ–Š       | 11/40 [00:16<00:42,  1.47s/it, training_loss=0.201]\u001b[A\n",
            "Epoch4:  28%|â–ˆâ–ˆâ–Š       | 11/40 [00:17<00:42,  1.47s/it, training_loss=0.142]\u001b[A\n",
            "Epoch4:  30%|â–ˆâ–ˆâ–ˆ       | 12/40 [00:17<00:41,  1.47s/it, training_loss=0.142]\u001b[A\n",
            "Epoch4:  30%|â–ˆâ–ˆâ–ˆ       | 12/40 [00:19<00:41,  1.47s/it, training_loss=0.115]\u001b[A\n",
            "Epoch4:  32%|â–ˆâ–ˆâ–ˆâ–Ž      | 13/40 [00:19<00:39,  1.47s/it, training_loss=0.115]\u001b[A\n",
            "Epoch4:  32%|â–ˆâ–ˆâ–ˆâ–Ž      | 13/40 [00:20<00:39,  1.47s/it, training_loss=0.128]\u001b[A\n",
            "Epoch4:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 14/40 [00:20<00:38,  1.48s/it, training_loss=0.128]\u001b[A\n",
            "Epoch4:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 14/40 [00:22<00:38,  1.48s/it, training_loss=0.154]\u001b[A\n",
            "Epoch4:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 15/40 [00:22<00:36,  1.48s/it, training_loss=0.154]\u001b[A\n",
            "Epoch4:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 15/40 [00:23<00:36,  1.48s/it, training_loss=0.223]\u001b[A\n",
            "Epoch4:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 16/40 [00:23<00:35,  1.48s/it, training_loss=0.223]\u001b[A\n",
            "Epoch4:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 16/40 [00:25<00:35,  1.48s/it, training_loss=0.146]\u001b[A\n",
            "Epoch4:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 17/40 [00:25<00:34,  1.48s/it, training_loss=0.146]\u001b[A\n",
            "Epoch4:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 17/40 [00:26<00:34,  1.48s/it, training_loss=0.191]\u001b[A\n",
            "Epoch4:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 18/40 [00:26<00:32,  1.48s/it, training_loss=0.191]\u001b[A\n",
            "Epoch4:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 18/40 [00:27<00:32,  1.48s/it, training_loss=0.178]\u001b[A\n",
            "Epoch4:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 19/40 [00:27<00:30,  1.48s/it, training_loss=0.178]\u001b[A\n",
            "Epoch4:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 19/40 [00:29<00:30,  1.48s/it, training_loss=0.235]\u001b[A\n",
            "Epoch4:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 20/40 [00:29<00:29,  1.47s/it, training_loss=0.235]\u001b[A\n",
            "Epoch4:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 20/40 [00:30<00:29,  1.47s/it, training_loss=0.092]\u001b[A\n",
            "Epoch4:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 21/40 [00:30<00:27,  1.47s/it, training_loss=0.092]\u001b[A\n",
            "Epoch4:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 21/40 [00:32<00:27,  1.47s/it, training_loss=0.146]\u001b[A\n",
            "Epoch4:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 22/40 [00:32<00:26,  1.47s/it, training_loss=0.146]\u001b[A\n",
            "Epoch4:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 22/40 [00:33<00:26,  1.47s/it, training_loss=0.189]\u001b[A\n",
            "Epoch4:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 23/40 [00:33<00:25,  1.47s/it, training_loss=0.189]\u001b[A\n",
            "Epoch4:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 23/40 [00:35<00:25,  1.47s/it, training_loss=0.153]\u001b[A\n",
            "Epoch4:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 24/40 [00:35<00:23,  1.47s/it, training_loss=0.153]\u001b[A\n",
            "Epoch4:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 24/40 [00:36<00:23,  1.47s/it, training_loss=0.118]\u001b[A\n",
            "Epoch4:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 25/40 [00:36<00:21,  1.47s/it, training_loss=0.118]\u001b[A\n",
            "Epoch4:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 25/40 [00:38<00:21,  1.47s/it, training_loss=0.193]\u001b[A\n",
            "Epoch4:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 26/40 [00:38<00:20,  1.47s/it, training_loss=0.193]\u001b[A\n",
            "Epoch4:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 26/40 [00:39<00:20,  1.47s/it, training_loss=0.138]\u001b[A\n",
            "Epoch4:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 27/40 [00:39<00:19,  1.46s/it, training_loss=0.138]\u001b[A\n",
            "Epoch4:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 27/40 [00:41<00:19,  1.46s/it, training_loss=0.124]\u001b[A\n",
            "Epoch4:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 28/40 [00:41<00:17,  1.47s/it, training_loss=0.124]\u001b[A\n",
            "Epoch4:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 28/40 [00:42<00:17,  1.47s/it, training_loss=0.120]\u001b[A\n",
            "Epoch4:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 29/40 [00:42<00:16,  1.47s/it, training_loss=0.120]\u001b[A\n",
            "Epoch4:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 29/40 [00:44<00:16,  1.47s/it, training_loss=0.057]\u001b[A\n",
            "Epoch4:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 30/40 [00:44<00:14,  1.47s/it, training_loss=0.057]\u001b[A\n",
            "Epoch4:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 30/40 [00:45<00:14,  1.47s/it, training_loss=0.098]\u001b[A\n",
            "Epoch4:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 31/40 [00:45<00:13,  1.47s/it, training_loss=0.098]\u001b[A\n",
            "Epoch4:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 31/40 [00:47<00:13,  1.47s/it, training_loss=0.251]\u001b[A\n",
            "Epoch4:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 32/40 [00:47<00:11,  1.46s/it, training_loss=0.251]\u001b[A\n",
            "Epoch4:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 32/40 [00:48<00:11,  1.46s/it, training_loss=0.206]\u001b[A\n",
            "Epoch4:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 33/40 [00:48<00:10,  1.47s/it, training_loss=0.206]\u001b[A\n",
            "Epoch4:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 33/40 [00:49<00:10,  1.47s/it, training_loss=0.134]\u001b[A\n",
            "Epoch4:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 34/40 [00:50<00:08,  1.47s/it, training_loss=0.134]\u001b[A\n",
            "Epoch4:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 34/40 [00:51<00:08,  1.47s/it, training_loss=0.128]\u001b[A\n",
            "Epoch4:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 35/40 [00:51<00:07,  1.47s/it, training_loss=0.128]\u001b[A\n",
            "Epoch4:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 35/40 [00:52<00:07,  1.47s/it, training_loss=0.123]\u001b[A\n",
            "Epoch4:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 36/40 [00:52<00:05,  1.47s/it, training_loss=0.123]\u001b[A\n",
            "Epoch4:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 36/40 [00:54<00:05,  1.47s/it, training_loss=0.152]\u001b[A\n",
            "Epoch4:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 37/40 [00:54<00:04,  1.47s/it, training_loss=0.152]\u001b[A\n",
            "Epoch4:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 37/40 [00:55<00:04,  1.47s/it, training_loss=0.119]\u001b[A\n",
            "Epoch4:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 38/40 [00:55<00:02,  1.47s/it, training_loss=0.119]\u001b[A\n",
            "Epoch4:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 38/40 [00:57<00:02,  1.47s/it, training_loss=0.177]\u001b[A\n",
            "Epoch4:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 39/40 [00:57<00:01,  1.47s/it, training_loss=0.177]\u001b[A\n",
            "Epoch4:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 39/40 [00:57<00:01,  1.47s/it, training_loss=0.310]\u001b[A\n",
            "Epoch4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:57<00:00,  1.18s/it, training_loss=0.310]\u001b[A\n",
            " 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [03:45<05:35, 55.99s/it]\n",
            "Epoch5:   0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch5:   0%|          | 0/40 [00:01<?, ?it/s, training_loss=0.147]\u001b[A\n",
            "Epoch5:   2%|â–Ž         | 1/40 [00:01<00:56,  1.46s/it, training_loss=0.147]\u001b[A\n",
            "Epoch5:   2%|â–Ž         | 1/40 [00:02<00:56,  1.46s/it, training_loss=0.122]\u001b[A\n",
            "Epoch5:   5%|â–Œ         | 2/40 [00:02<00:55,  1.47s/it, training_loss=0.122]\u001b[A\n",
            "Epoch5:   5%|â–Œ         | 2/40 [00:04<00:55,  1.47s/it, training_loss=0.155]\u001b[A\n",
            "Epoch5:   8%|â–Š         | 3/40 [00:04<00:54,  1.47s/it, training_loss=0.155]\u001b[A\n",
            "Epoch5:   8%|â–Š         | 3/40 [00:05<00:54,  1.47s/it, training_loss=0.206]\u001b[A\n",
            "Epoch5:  10%|â–ˆ         | 4/40 [00:05<00:52,  1.46s/it, training_loss=0.206]\u001b[A\n",
            "Epoch5:  10%|â–ˆ         | 4/40 [00:07<00:52,  1.46s/it, training_loss=0.148]\u001b[A\n",
            "Epoch5:  12%|â–ˆâ–Ž        | 5/40 [00:07<00:51,  1.46s/it, training_loss=0.148]\u001b[A\n",
            "Epoch5:  12%|â–ˆâ–Ž        | 5/40 [00:08<00:51,  1.46s/it, training_loss=0.061]\u001b[A\n",
            "Epoch5:  15%|â–ˆâ–Œ        | 6/40 [00:08<00:49,  1.47s/it, training_loss=0.061]\u001b[A\n",
            "Epoch5:  15%|â–ˆâ–Œ        | 6/40 [00:10<00:49,  1.47s/it, training_loss=0.129]\u001b[A\n",
            "Epoch5:  18%|â–ˆâ–Š        | 7/40 [00:10<00:48,  1.47s/it, training_loss=0.129]\u001b[A\n",
            "Epoch5:  18%|â–ˆâ–Š        | 7/40 [00:11<00:48,  1.47s/it, training_loss=0.190]\u001b[A\n",
            "Epoch5:  20%|â–ˆâ–ˆ        | 8/40 [00:11<00:46,  1.47s/it, training_loss=0.190]\u001b[A\n",
            "Epoch5:  20%|â–ˆâ–ˆ        | 8/40 [00:13<00:46,  1.47s/it, training_loss=0.123]\u001b[A\n",
            "Epoch5:  22%|â–ˆâ–ˆâ–Ž       | 9/40 [00:13<00:45,  1.47s/it, training_loss=0.123]\u001b[A\n",
            "Epoch5:  22%|â–ˆâ–ˆâ–Ž       | 9/40 [00:14<00:45,  1.47s/it, training_loss=0.204]\u001b[A\n",
            "Epoch5:  25%|â–ˆâ–ˆâ–Œ       | 10/40 [00:14<00:43,  1.46s/it, training_loss=0.204]\u001b[A\n",
            "Epoch5:  25%|â–ˆâ–ˆâ–Œ       | 10/40 [00:16<00:43,  1.46s/it, training_loss=0.192]\u001b[A\n",
            "Epoch5:  28%|â–ˆâ–ˆâ–Š       | 11/40 [00:16<00:42,  1.46s/it, training_loss=0.192]\u001b[A\n",
            "Epoch5:  28%|â–ˆâ–ˆâ–Š       | 11/40 [00:17<00:42,  1.46s/it, training_loss=0.163]\u001b[A\n",
            "Epoch5:  30%|â–ˆâ–ˆâ–ˆ       | 12/40 [00:17<00:40,  1.46s/it, training_loss=0.163]\u001b[A\n",
            "Epoch5:  30%|â–ˆâ–ˆâ–ˆ       | 12/40 [00:19<00:40,  1.46s/it, training_loss=0.136]\u001b[A\n",
            "Epoch5:  32%|â–ˆâ–ˆâ–ˆâ–Ž      | 13/40 [00:19<00:39,  1.46s/it, training_loss=0.136]\u001b[A\n",
            "Epoch5:  32%|â–ˆâ–ˆâ–ˆâ–Ž      | 13/40 [00:20<00:39,  1.46s/it, training_loss=0.181]\u001b[A\n",
            "Epoch5:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 14/40 [00:20<00:38,  1.46s/it, training_loss=0.181]\u001b[A\n",
            "Epoch5:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 14/40 [00:21<00:38,  1.46s/it, training_loss=0.250]\u001b[A\n",
            "Epoch5:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 15/40 [00:21<00:36,  1.46s/it, training_loss=0.250]\u001b[A\n",
            "Epoch5:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 15/40 [00:23<00:36,  1.46s/it, training_loss=0.157]\u001b[A\n",
            "Epoch5:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 16/40 [00:23<00:34,  1.46s/it, training_loss=0.157]\u001b[A\n",
            "Epoch5:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 16/40 [00:24<00:34,  1.46s/it, training_loss=0.054]\u001b[A\n",
            "Epoch5:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 17/40 [00:24<00:33,  1.46s/it, training_loss=0.054]\u001b[A\n",
            "Epoch5:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 17/40 [00:26<00:33,  1.46s/it, training_loss=0.146]\u001b[A\n",
            "Epoch5:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 18/40 [00:26<00:32,  1.46s/it, training_loss=0.146]\u001b[A\n",
            "Epoch5:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 18/40 [00:27<00:32,  1.46s/it, training_loss=0.207]\u001b[A\n",
            "Epoch5:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 19/40 [00:27<00:30,  1.46s/it, training_loss=0.207]\u001b[A\n",
            "Epoch5:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 19/40 [00:29<00:30,  1.46s/it, training_loss=0.162]\u001b[A\n",
            "Epoch5:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 20/40 [00:29<00:29,  1.46s/it, training_loss=0.162]\u001b[A\n",
            "Epoch5:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 20/40 [00:30<00:29,  1.46s/it, training_loss=0.089]\u001b[A\n",
            "Epoch5:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 21/40 [00:30<00:27,  1.46s/it, training_loss=0.089]\u001b[A\n",
            "Epoch5:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 21/40 [00:32<00:27,  1.46s/it, training_loss=0.114]\u001b[A\n",
            "Epoch5:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 22/40 [00:32<00:26,  1.47s/it, training_loss=0.114]\u001b[A\n",
            "Epoch5:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 22/40 [00:33<00:26,  1.47s/it, training_loss=0.105]\u001b[A\n",
            "Epoch5:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 23/40 [00:33<00:24,  1.46s/it, training_loss=0.105]\u001b[A\n",
            "Epoch5:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 23/40 [00:35<00:24,  1.46s/it, training_loss=0.089]\u001b[A\n",
            "Epoch5:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 24/40 [00:35<00:23,  1.46s/it, training_loss=0.089]\u001b[A\n",
            "Epoch5:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 24/40 [00:36<00:23,  1.46s/it, training_loss=0.106]\u001b[A\n",
            "Epoch5:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 25/40 [00:36<00:21,  1.46s/it, training_loss=0.106]\u001b[A\n",
            "Epoch5:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 25/40 [00:38<00:21,  1.46s/it, training_loss=0.132]\u001b[A\n",
            "Epoch5:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 26/40 [00:38<00:20,  1.47s/it, training_loss=0.132]\u001b[A\n",
            "Epoch5:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 26/40 [00:39<00:20,  1.47s/it, training_loss=0.190]\u001b[A\n",
            "Epoch5:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 27/40 [00:39<00:19,  1.47s/it, training_loss=0.190]\u001b[A\n",
            "Epoch5:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 27/40 [00:40<00:19,  1.47s/it, training_loss=0.160]\u001b[A\n",
            "Epoch5:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 28/40 [00:40<00:17,  1.47s/it, training_loss=0.160]\u001b[A\n",
            "Epoch5:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 28/40 [00:42<00:17,  1.47s/it, training_loss=0.102]\u001b[A\n",
            "Epoch5:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 29/40 [00:42<00:16,  1.47s/it, training_loss=0.102]\u001b[A\n",
            "Epoch5:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 29/40 [00:43<00:16,  1.47s/it, training_loss=0.113]\u001b[A\n",
            "Epoch5:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 30/40 [00:43<00:14,  1.47s/it, training_loss=0.113]\u001b[A\n",
            "Epoch5:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 30/40 [00:45<00:14,  1.47s/it, training_loss=0.067]\u001b[A\n",
            "Epoch5:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 31/40 [00:45<00:13,  1.47s/it, training_loss=0.067]\u001b[A\n",
            "Epoch5:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 31/40 [00:46<00:13,  1.47s/it, training_loss=0.101]\u001b[A\n",
            "Epoch5:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 32/40 [00:46<00:11,  1.47s/it, training_loss=0.101]\u001b[A\n",
            "Epoch5:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 32/40 [00:48<00:11,  1.47s/it, training_loss=0.165]\u001b[A\n",
            "Epoch5:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 33/40 [00:48<00:10,  1.47s/it, training_loss=0.165]\u001b[A\n",
            "Epoch5:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 33/40 [00:49<00:10,  1.47s/it, training_loss=0.226]\u001b[A\n",
            "Epoch5:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 34/40 [00:49<00:08,  1.47s/it, training_loss=0.226]\u001b[A\n",
            "Epoch5:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 34/40 [00:51<00:08,  1.47s/it, training_loss=0.192]\u001b[A\n",
            "Epoch5:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 35/40 [00:51<00:07,  1.47s/it, training_loss=0.192]\u001b[A\n",
            "Epoch5:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 35/40 [00:52<00:07,  1.47s/it, training_loss=0.141]\u001b[A\n",
            "Epoch5:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 36/40 [00:52<00:05,  1.47s/it, training_loss=0.141]\u001b[A\n",
            "Epoch5:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 36/40 [00:54<00:05,  1.47s/it, training_loss=0.206]\u001b[A\n",
            "Epoch5:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 37/40 [00:54<00:04,  1.47s/it, training_loss=0.206]\u001b[A\n",
            "Epoch5:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 37/40 [00:55<00:04,  1.47s/it, training_loss=0.087]\u001b[A\n",
            "Epoch5:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 38/40 [00:55<00:02,  1.47s/it, training_loss=0.087]\u001b[A\n",
            "Epoch5:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 38/40 [00:57<00:02,  1.47s/it, training_loss=0.077]\u001b[A\n",
            "Epoch5:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 39/40 [00:57<00:01,  1.47s/it, training_loss=0.077]\u001b[A\n",
            "Epoch5:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 39/40 [00:57<00:01,  1.47s/it, training_loss=0.080]\u001b[A\n",
            "Epoch5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:57<00:00,  1.18s/it, training_loss=0.080]\u001b[A\n",
            " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [04:43<04:42, 56.48s/it]\n",
            "Epoch6:   0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch6:   0%|          | 0/40 [00:01<?, ?it/s, training_loss=0.126]\u001b[A\n",
            "Epoch6:   2%|â–Ž         | 1/40 [00:01<00:56,  1.45s/it, training_loss=0.126]\u001b[A\n",
            "Epoch6:   2%|â–Ž         | 1/40 [00:02<00:56,  1.45s/it, training_loss=0.149]\u001b[A\n",
            "Epoch6:   5%|â–Œ         | 2/40 [00:02<00:55,  1.45s/it, training_loss=0.149]\u001b[A\n",
            "Epoch6:   5%|â–Œ         | 2/40 [00:04<00:55,  1.45s/it, training_loss=0.201]\u001b[A\n",
            "Epoch6:   8%|â–Š         | 3/40 [00:04<00:53,  1.46s/it, training_loss=0.201]\u001b[A\n",
            "Epoch6:   8%|â–Š         | 3/40 [00:05<00:53,  1.46s/it, training_loss=0.228]\u001b[A\n",
            "Epoch6:  10%|â–ˆ         | 4/40 [00:05<00:52,  1.46s/it, training_loss=0.228]\u001b[A\n",
            "Epoch6:  10%|â–ˆ         | 4/40 [00:07<00:52,  1.46s/it, training_loss=0.149]\u001b[A\n",
            "Epoch6:  12%|â–ˆâ–Ž        | 5/40 [00:07<00:51,  1.46s/it, training_loss=0.149]\u001b[A\n",
            "Epoch6:  12%|â–ˆâ–Ž        | 5/40 [00:08<00:51,  1.46s/it, training_loss=0.086]\u001b[A\n",
            "Epoch6:  15%|â–ˆâ–Œ        | 6/40 [00:08<00:49,  1.46s/it, training_loss=0.086]\u001b[A\n",
            "Epoch6:  15%|â–ˆâ–Œ        | 6/40 [00:10<00:49,  1.46s/it, training_loss=0.060]\u001b[A\n",
            "Epoch6:  18%|â–ˆâ–Š        | 7/40 [00:10<00:48,  1.46s/it, training_loss=0.060]\u001b[A\n",
            "Epoch6:  18%|â–ˆâ–Š        | 7/40 [00:11<00:48,  1.46s/it, training_loss=0.091]\u001b[A\n",
            "Epoch6:  20%|â–ˆâ–ˆ        | 8/40 [00:11<00:46,  1.46s/it, training_loss=0.091]\u001b[A\n",
            "Epoch6:  20%|â–ˆâ–ˆ        | 8/40 [00:13<00:46,  1.46s/it, training_loss=0.094]\u001b[A\n",
            "Epoch6:  22%|â–ˆâ–ˆâ–Ž       | 9/40 [00:13<00:45,  1.46s/it, training_loss=0.094]\u001b[A\n",
            "Epoch6:  22%|â–ˆâ–ˆâ–Ž       | 9/40 [00:14<00:45,  1.46s/it, training_loss=0.134]\u001b[A\n",
            "Epoch6:  25%|â–ˆâ–ˆâ–Œ       | 10/40 [00:14<00:43,  1.46s/it, training_loss=0.134]\u001b[A\n",
            "Epoch6:  25%|â–ˆâ–ˆâ–Œ       | 10/40 [00:16<00:43,  1.46s/it, training_loss=0.131]\u001b[A\n",
            "Epoch6:  28%|â–ˆâ–ˆâ–Š       | 11/40 [00:16<00:42,  1.46s/it, training_loss=0.131]\u001b[A\n",
            "Epoch6:  28%|â–ˆâ–ˆâ–Š       | 11/40 [00:17<00:42,  1.46s/it, training_loss=0.109]\u001b[A\n",
            "Epoch6:  30%|â–ˆâ–ˆâ–ˆ       | 12/40 [00:17<00:40,  1.46s/it, training_loss=0.109]\u001b[A\n",
            "Epoch6:  30%|â–ˆâ–ˆâ–ˆ       | 12/40 [00:19<00:40,  1.46s/it, training_loss=0.133]\u001b[A\n",
            "Epoch6:  32%|â–ˆâ–ˆâ–ˆâ–Ž      | 13/40 [00:19<00:39,  1.47s/it, training_loss=0.133]\u001b[A\n",
            "Epoch6:  32%|â–ˆâ–ˆâ–ˆâ–Ž      | 13/40 [00:20<00:39,  1.47s/it, training_loss=0.101]\u001b[A\n",
            "Epoch6:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 14/40 [00:20<00:38,  1.47s/it, training_loss=0.101]\u001b[A\n",
            "Epoch6:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 14/40 [00:21<00:38,  1.47s/it, training_loss=0.150]\u001b[A\n",
            "Epoch6:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 15/40 [00:21<00:36,  1.47s/it, training_loss=0.150]\u001b[A\n",
            "Epoch6:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 15/40 [00:23<00:36,  1.47s/it, training_loss=0.123]\u001b[A\n",
            "Epoch6:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 16/40 [00:23<00:35,  1.47s/it, training_loss=0.123]\u001b[A\n",
            "Epoch6:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 16/40 [00:24<00:35,  1.47s/it, training_loss=0.183]\u001b[A\n",
            "Epoch6:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 17/40 [00:24<00:33,  1.47s/it, training_loss=0.183]\u001b[A\n",
            "Epoch6:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 17/40 [00:26<00:33,  1.47s/it, training_loss=0.132]\u001b[A\n",
            "Epoch6:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 18/40 [00:26<00:32,  1.47s/it, training_loss=0.132]\u001b[A\n",
            "Epoch6:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 18/40 [00:27<00:32,  1.47s/it, training_loss=0.126]\u001b[A\n",
            "Epoch6:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 19/40 [00:27<00:30,  1.47s/it, training_loss=0.126]\u001b[A\n",
            "Epoch6:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 19/40 [00:29<00:30,  1.47s/it, training_loss=0.162]\u001b[A\n",
            "Epoch6:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 20/40 [00:29<00:29,  1.46s/it, training_loss=0.162]\u001b[A\n",
            "Epoch6:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 20/40 [00:30<00:29,  1.46s/it, training_loss=0.090]\u001b[A\n",
            "Epoch6:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 21/40 [00:30<00:27,  1.47s/it, training_loss=0.090]\u001b[A\n",
            "Epoch6:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 21/40 [00:32<00:27,  1.47s/it, training_loss=0.162]\u001b[A\n",
            "Epoch6:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 22/40 [00:32<00:26,  1.47s/it, training_loss=0.162]\u001b[A\n",
            "Epoch6:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 22/40 [00:33<00:26,  1.47s/it, training_loss=0.198]\u001b[A\n",
            "Epoch6:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 23/40 [00:33<00:24,  1.47s/it, training_loss=0.198]\u001b[A\n",
            "Epoch6:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 23/40 [00:35<00:24,  1.47s/it, training_loss=0.122]\u001b[A\n",
            "Epoch6:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 24/40 [00:35<00:23,  1.47s/it, training_loss=0.122]\u001b[A\n",
            "Epoch6:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 24/40 [00:36<00:23,  1.47s/it, training_loss=0.049]\u001b[A\n",
            "Epoch6:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 25/40 [00:36<00:22,  1.47s/it, training_loss=0.049]\u001b[A\n",
            "Epoch6:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 25/40 [00:38<00:22,  1.47s/it, training_loss=0.164]\u001b[A\n",
            "Epoch6:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 26/40 [00:38<00:20,  1.47s/it, training_loss=0.164]\u001b[A\n",
            "Epoch6:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 26/40 [00:39<00:20,  1.47s/it, training_loss=0.114]\u001b[A\n",
            "Epoch6:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 27/40 [00:39<00:19,  1.47s/it, training_loss=0.114]\u001b[A\n",
            "Epoch6:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 27/40 [00:41<00:19,  1.47s/it, training_loss=0.217]\u001b[A\n",
            "Epoch6:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 28/40 [00:41<00:17,  1.47s/it, training_loss=0.217]\u001b[A\n",
            "Epoch6:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 28/40 [00:42<00:17,  1.47s/it, training_loss=0.154]\u001b[A\n",
            "Epoch6:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 29/40 [00:42<00:16,  1.47s/it, training_loss=0.154]\u001b[A\n",
            "Epoch6:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 29/40 [00:43<00:16,  1.47s/it, training_loss=0.131]\u001b[A\n",
            "Epoch6:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 30/40 [00:43<00:14,  1.47s/it, training_loss=0.131]\u001b[A\n",
            "Epoch6:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 30/40 [00:45<00:14,  1.47s/it, training_loss=0.182]\u001b[A\n",
            "Epoch6:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 31/40 [00:45<00:13,  1.47s/it, training_loss=0.182]\u001b[A\n",
            "Epoch6:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 31/40 [00:46<00:13,  1.47s/it, training_loss=0.115]\u001b[A\n",
            "Epoch6:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 32/40 [00:46<00:11,  1.47s/it, training_loss=0.115]\u001b[A\n",
            "Epoch6:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 32/40 [00:48<00:11,  1.47s/it, training_loss=0.141]\u001b[A\n",
            "Epoch6:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 33/40 [00:48<00:10,  1.47s/it, training_loss=0.141]\u001b[A\n",
            "Epoch6:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 33/40 [00:49<00:10,  1.47s/it, training_loss=0.092]\u001b[A\n",
            "Epoch6:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 34/40 [00:49<00:08,  1.47s/it, training_loss=0.092]\u001b[A\n",
            "Epoch6:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 34/40 [00:51<00:08,  1.47s/it, training_loss=0.093]\u001b[A\n",
            "Epoch6:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 35/40 [00:51<00:07,  1.47s/it, training_loss=0.093]\u001b[A\n",
            "Epoch6:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 35/40 [00:52<00:07,  1.47s/it, training_loss=0.099]\u001b[A\n",
            "Epoch6:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 36/40 [00:52<00:05,  1.47s/it, training_loss=0.099]\u001b[A\n",
            "Epoch6:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 36/40 [00:54<00:05,  1.47s/it, training_loss=0.081]\u001b[A\n",
            "Epoch6:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 37/40 [00:54<00:04,  1.47s/it, training_loss=0.081]\u001b[A\n",
            "Epoch6:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 37/40 [00:55<00:04,  1.47s/it, training_loss=0.074]\u001b[A\n",
            "Epoch6:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 38/40 [00:55<00:02,  1.47s/it, training_loss=0.074]\u001b[A\n",
            "Epoch6:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 38/40 [00:57<00:02,  1.47s/it, training_loss=0.130]\u001b[A\n",
            "Epoch6:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 39/40 [00:57<00:01,  1.47s/it, training_loss=0.130]\u001b[A\n",
            "Epoch6:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 39/40 [00:57<00:01,  1.47s/it, training_loss=0.281]\u001b[A\n",
            "Epoch6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:57<00:00,  1.18s/it, training_loss=0.281]\u001b[A\n",
            " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [05:40<03:47, 56.86s/it]\n",
            "Epoch7:   0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch7:   0%|          | 0/40 [00:01<?, ?it/s, training_loss=0.115]\u001b[A\n",
            "Epoch7:   2%|â–Ž         | 1/40 [00:01<00:56,  1.45s/it, training_loss=0.115]\u001b[A\n",
            "Epoch7:   2%|â–Ž         | 1/40 [00:02<00:56,  1.45s/it, training_loss=0.106]\u001b[A\n",
            "Epoch7:   5%|â–Œ         | 2/40 [00:02<00:55,  1.45s/it, training_loss=0.106]\u001b[A\n",
            "Epoch7:   5%|â–Œ         | 2/40 [00:04<00:55,  1.45s/it, training_loss=0.139]\u001b[A\n",
            "Epoch7:   8%|â–Š         | 3/40 [00:04<00:53,  1.46s/it, training_loss=0.139]\u001b[A\n",
            "Epoch7:   8%|â–Š         | 3/40 [00:05<00:53,  1.46s/it, training_loss=0.143]\u001b[A\n",
            "Epoch7:  10%|â–ˆ         | 4/40 [00:05<00:52,  1.46s/it, training_loss=0.143]\u001b[A\n",
            "Epoch7:  10%|â–ˆ         | 4/40 [00:07<00:52,  1.46s/it, training_loss=0.133]\u001b[A\n",
            "Epoch7:  12%|â–ˆâ–Ž        | 5/40 [00:07<00:51,  1.46s/it, training_loss=0.133]\u001b[A\n",
            "Epoch7:  12%|â–ˆâ–Ž        | 5/40 [00:08<00:51,  1.46s/it, training_loss=0.134]\u001b[A\n",
            "Epoch7:  15%|â–ˆâ–Œ        | 6/40 [00:08<00:49,  1.46s/it, training_loss=0.134]\u001b[A\n",
            "Epoch7:  15%|â–ˆâ–Œ        | 6/40 [00:10<00:49,  1.46s/it, training_loss=0.166]\u001b[A\n",
            "Epoch7:  18%|â–ˆâ–Š        | 7/40 [00:10<00:48,  1.46s/it, training_loss=0.166]\u001b[A\n",
            "Epoch7:  18%|â–ˆâ–Š        | 7/40 [00:11<00:48,  1.46s/it, training_loss=0.170]\u001b[A\n",
            "Epoch7:  20%|â–ˆâ–ˆ        | 8/40 [00:11<00:46,  1.47s/it, training_loss=0.170]\u001b[A\n",
            "Epoch7:  20%|â–ˆâ–ˆ        | 8/40 [00:13<00:46,  1.47s/it, training_loss=0.173]\u001b[A\n",
            "Epoch7:  22%|â–ˆâ–ˆâ–Ž       | 9/40 [00:13<00:45,  1.47s/it, training_loss=0.173]\u001b[A\n",
            "Epoch7:  22%|â–ˆâ–ˆâ–Ž       | 9/40 [00:14<00:45,  1.47s/it, training_loss=0.147]\u001b[A\n",
            "Epoch7:  25%|â–ˆâ–ˆâ–Œ       | 10/40 [00:14<00:44,  1.47s/it, training_loss=0.147]\u001b[A\n",
            "Epoch7:  25%|â–ˆâ–ˆâ–Œ       | 10/40 [00:16<00:44,  1.47s/it, training_loss=0.123]\u001b[A\n",
            "Epoch7:  28%|â–ˆâ–ˆâ–Š       | 11/40 [00:16<00:42,  1.47s/it, training_loss=0.123]\u001b[A\n",
            "Epoch7:  28%|â–ˆâ–ˆâ–Š       | 11/40 [00:17<00:42,  1.47s/it, training_loss=0.050]\u001b[A\n",
            "Epoch7:  30%|â–ˆâ–ˆâ–ˆ       | 12/40 [00:17<00:41,  1.47s/it, training_loss=0.050]\u001b[A\n",
            "Epoch7:  30%|â–ˆâ–ˆâ–ˆ       | 12/40 [00:19<00:41,  1.47s/it, training_loss=0.245]\u001b[A\n",
            "Epoch7:  32%|â–ˆâ–ˆâ–ˆâ–Ž      | 13/40 [00:19<00:39,  1.47s/it, training_loss=0.245]\u001b[A\n",
            "Epoch7:  32%|â–ˆâ–ˆâ–ˆâ–Ž      | 13/40 [00:20<00:39,  1.47s/it, training_loss=0.121]\u001b[A\n",
            "Epoch7:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 14/40 [00:20<00:38,  1.47s/it, training_loss=0.121]\u001b[A\n",
            "Epoch7:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 14/40 [00:21<00:38,  1.47s/it, training_loss=0.120]\u001b[A\n",
            "Epoch7:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 15/40 [00:21<00:36,  1.47s/it, training_loss=0.120]\u001b[A\n",
            "Epoch7:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 15/40 [00:23<00:36,  1.47s/it, training_loss=0.108]\u001b[A\n",
            "Epoch7:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 16/40 [00:23<00:35,  1.47s/it, training_loss=0.108]\u001b[A\n",
            "Epoch7:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 16/40 [00:24<00:35,  1.47s/it, training_loss=0.174]\u001b[A\n",
            "Epoch7:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 17/40 [00:24<00:33,  1.47s/it, training_loss=0.174]\u001b[A\n",
            "Epoch7:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 17/40 [00:26<00:33,  1.47s/it, training_loss=0.090]\u001b[A\n",
            "Epoch7:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 18/40 [00:26<00:32,  1.47s/it, training_loss=0.090]\u001b[A\n",
            "Epoch7:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 18/40 [00:27<00:32,  1.47s/it, training_loss=0.169]\u001b[A\n",
            "Epoch7:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 19/40 [00:27<00:30,  1.47s/it, training_loss=0.169]\u001b[A\n",
            "Epoch7:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 19/40 [00:29<00:30,  1.47s/it, training_loss=0.027]\u001b[A\n",
            "Epoch7:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 20/40 [00:29<00:29,  1.47s/it, training_loss=0.027]\u001b[A\n",
            "Epoch7:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 20/40 [00:30<00:29,  1.47s/it, training_loss=0.097]\u001b[A\n",
            "Epoch7:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 21/40 [00:30<00:27,  1.47s/it, training_loss=0.097]\u001b[A\n",
            "Epoch7:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 21/40 [00:32<00:27,  1.47s/it, training_loss=0.164]\u001b[A\n",
            "Epoch7:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 22/40 [00:32<00:26,  1.47s/it, training_loss=0.164]\u001b[A\n",
            "Epoch7:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 22/40 [00:33<00:26,  1.47s/it, training_loss=0.084]\u001b[A\n",
            "Epoch7:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 23/40 [00:33<00:24,  1.47s/it, training_loss=0.084]\u001b[A\n",
            "Epoch7:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 23/40 [00:35<00:24,  1.47s/it, training_loss=0.070]\u001b[A\n",
            "Epoch7:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 24/40 [00:35<00:23,  1.47s/it, training_loss=0.070]\u001b[A\n",
            "Epoch7:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 24/40 [00:36<00:23,  1.47s/it, training_loss=0.131]\u001b[A\n",
            "Epoch7:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 25/40 [00:36<00:22,  1.47s/it, training_loss=0.131]\u001b[A\n",
            "Epoch7:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 25/40 [00:38<00:22,  1.47s/it, training_loss=0.100]\u001b[A\n",
            "Epoch7:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 26/40 [00:38<00:20,  1.47s/it, training_loss=0.100]\u001b[A\n",
            "Epoch7:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 26/40 [00:39<00:20,  1.47s/it, training_loss=0.187]\u001b[A\n",
            "Epoch7:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 27/40 [00:39<00:19,  1.47s/it, training_loss=0.187]\u001b[A\n",
            "Epoch7:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 27/40 [00:41<00:19,  1.47s/it, training_loss=0.085]\u001b[A\n",
            "Epoch7:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 28/40 [00:41<00:17,  1.47s/it, training_loss=0.085]\u001b[A\n",
            "Epoch7:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 28/40 [00:42<00:17,  1.47s/it, training_loss=0.159]\u001b[A\n",
            "Epoch7:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 29/40 [00:42<00:16,  1.47s/it, training_loss=0.159]\u001b[A\n",
            "Epoch7:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 29/40 [00:44<00:16,  1.47s/it, training_loss=0.147]\u001b[A\n",
            "Epoch7:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 30/40 [00:44<00:14,  1.47s/it, training_loss=0.147]\u001b[A\n",
            "Epoch7:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 30/40 [00:45<00:14,  1.47s/it, training_loss=0.110]\u001b[A\n",
            "Epoch7:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 31/40 [00:45<00:13,  1.47s/it, training_loss=0.110]\u001b[A\n",
            "Epoch7:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 31/40 [00:46<00:13,  1.47s/it, training_loss=0.112]\u001b[A\n",
            "Epoch7:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 32/40 [00:46<00:11,  1.47s/it, training_loss=0.112]\u001b[A\n",
            "Epoch7:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 32/40 [00:48<00:11,  1.47s/it, training_loss=0.074]\u001b[A\n",
            "Epoch7:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 33/40 [00:48<00:10,  1.47s/it, training_loss=0.074]\u001b[A\n",
            "Epoch7:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 33/40 [00:49<00:10,  1.47s/it, training_loss=0.097]\u001b[A\n",
            "Epoch7:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 34/40 [00:49<00:08,  1.47s/it, training_loss=0.097]\u001b[A\n",
            "Epoch7:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 34/40 [00:51<00:08,  1.47s/it, training_loss=0.095]\u001b[A\n",
            "Epoch7:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 35/40 [00:51<00:07,  1.47s/it, training_loss=0.095]\u001b[A\n",
            "Epoch7:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 35/40 [00:52<00:07,  1.47s/it, training_loss=0.081]\u001b[A\n",
            "Epoch7:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 36/40 [00:52<00:05,  1.47s/it, training_loss=0.081]\u001b[A\n",
            "Epoch7:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 36/40 [00:54<00:05,  1.47s/it, training_loss=0.025]\u001b[A\n",
            "Epoch7:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 37/40 [00:54<00:04,  1.47s/it, training_loss=0.025]\u001b[A\n",
            "Epoch7:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 37/40 [00:55<00:04,  1.47s/it, training_loss=0.129]\u001b[A\n",
            "Epoch7:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 38/40 [00:55<00:02,  1.47s/it, training_loss=0.129]\u001b[A\n",
            "Epoch7:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 38/40 [00:57<00:02,  1.47s/it, training_loss=0.110]\u001b[A\n",
            "Epoch7:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 39/40 [00:57<00:01,  1.47s/it, training_loss=0.110]\u001b[A\n",
            "Epoch7:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 39/40 [00:57<00:01,  1.47s/it, training_loss=0.121]\u001b[A\n",
            "Epoch7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:57<00:00,  1.18s/it, training_loss=0.121]\u001b[A\n",
            " 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [06:38<02:51, 57.13s/it]\n",
            "Epoch8:   0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch8:   0%|          | 0/40 [00:01<?, ?it/s, training_loss=0.093]\u001b[A\n",
            "Epoch8:   2%|â–Ž         | 1/40 [00:01<00:57,  1.47s/it, training_loss=0.093]\u001b[A\n",
            "Epoch8:   2%|â–Ž         | 1/40 [00:02<00:57,  1.47s/it, training_loss=0.094]\u001b[A\n",
            "Epoch8:   5%|â–Œ         | 2/40 [00:02<00:55,  1.47s/it, training_loss=0.094]\u001b[A\n",
            "Epoch8:   5%|â–Œ         | 2/40 [00:04<00:55,  1.47s/it, training_loss=0.304]\u001b[A\n",
            "Epoch8:   8%|â–Š         | 3/40 [00:04<00:54,  1.47s/it, training_loss=0.304]\u001b[A\n",
            "Epoch8:   8%|â–Š         | 3/40 [00:05<00:54,  1.47s/it, training_loss=0.124]\u001b[A\n",
            "Epoch8:  10%|â–ˆ         | 4/40 [00:05<00:52,  1.47s/it, training_loss=0.124]\u001b[A\n",
            "Epoch8:  10%|â–ˆ         | 4/40 [00:07<00:52,  1.47s/it, training_loss=0.120]\u001b[A\n",
            "Epoch8:  12%|â–ˆâ–Ž        | 5/40 [00:07<00:51,  1.47s/it, training_loss=0.120]\u001b[A\n",
            "Epoch8:  12%|â–ˆâ–Ž        | 5/40 [00:08<00:51,  1.47s/it, training_loss=0.069]\u001b[A\n",
            "Epoch8:  15%|â–ˆâ–Œ        | 6/40 [00:08<00:49,  1.47s/it, training_loss=0.069]\u001b[A\n",
            "Epoch8:  15%|â–ˆâ–Œ        | 6/40 [00:10<00:49,  1.47s/it, training_loss=0.062]\u001b[A\n",
            "Epoch8:  18%|â–ˆâ–Š        | 7/40 [00:10<00:48,  1.47s/it, training_loss=0.062]\u001b[A\n",
            "Epoch8:  18%|â–ˆâ–Š        | 7/40 [00:11<00:48,  1.47s/it, training_loss=0.229]\u001b[A\n",
            "Epoch8:  20%|â–ˆâ–ˆ        | 8/40 [00:11<00:47,  1.47s/it, training_loss=0.229]\u001b[A\n",
            "Epoch8:  20%|â–ˆâ–ˆ        | 8/40 [00:13<00:47,  1.47s/it, training_loss=0.128]\u001b[A\n",
            "Epoch8:  22%|â–ˆâ–ˆâ–Ž       | 9/40 [00:13<00:45,  1.47s/it, training_loss=0.128]\u001b[A\n",
            "Epoch8:  22%|â–ˆâ–ˆâ–Ž       | 9/40 [00:14<00:45,  1.47s/it, training_loss=0.105]\u001b[A\n",
            "Epoch8:  25%|â–ˆâ–ˆâ–Œ       | 10/40 [00:14<00:43,  1.47s/it, training_loss=0.105]\u001b[A\n",
            "Epoch8:  25%|â–ˆâ–ˆâ–Œ       | 10/40 [00:16<00:43,  1.47s/it, training_loss=0.046]\u001b[A\n",
            "Epoch8:  28%|â–ˆâ–ˆâ–Š       | 11/40 [00:16<00:42,  1.47s/it, training_loss=0.046]\u001b[A\n",
            "Epoch8:  28%|â–ˆâ–ˆâ–Š       | 11/40 [00:17<00:42,  1.47s/it, training_loss=0.110]\u001b[A\n",
            "Epoch8:  30%|â–ˆâ–ˆâ–ˆ       | 12/40 [00:17<00:41,  1.47s/it, training_loss=0.110]\u001b[A\n",
            "Epoch8:  30%|â–ˆâ–ˆâ–ˆ       | 12/40 [00:19<00:41,  1.47s/it, training_loss=0.050]\u001b[A\n",
            "Epoch8:  32%|â–ˆâ–ˆâ–ˆâ–Ž      | 13/40 [00:19<00:39,  1.47s/it, training_loss=0.050]\u001b[A\n",
            "Epoch8:  32%|â–ˆâ–ˆâ–ˆâ–Ž      | 13/40 [00:20<00:39,  1.47s/it, training_loss=0.137]\u001b[A\n",
            "Epoch8:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 14/40 [00:20<00:38,  1.47s/it, training_loss=0.137]\u001b[A\n",
            "Epoch8:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 14/40 [00:22<00:38,  1.47s/it, training_loss=0.039]\u001b[A\n",
            "Epoch8:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 15/40 [00:22<00:36,  1.48s/it, training_loss=0.039]\u001b[A\n",
            "Epoch8:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 15/40 [00:23<00:36,  1.48s/it, training_loss=0.048]\u001b[A\n",
            "Epoch8:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 16/40 [00:23<00:35,  1.48s/it, training_loss=0.048]\u001b[A\n",
            "Epoch8:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 16/40 [00:25<00:35,  1.48s/it, training_loss=0.154]\u001b[A\n",
            "Epoch8:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 17/40 [00:25<00:33,  1.47s/it, training_loss=0.154]\u001b[A\n",
            "Epoch8:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 17/40 [00:26<00:33,  1.47s/it, training_loss=0.209]\u001b[A\n",
            "Epoch8:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 18/40 [00:26<00:32,  1.47s/it, training_loss=0.209]\u001b[A\n",
            "Epoch8:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 18/40 [00:27<00:32,  1.47s/it, training_loss=0.103]\u001b[A\n",
            "Epoch8:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 19/40 [00:27<00:30,  1.47s/it, training_loss=0.103]\u001b[A\n",
            "Epoch8:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 19/40 [00:29<00:30,  1.47s/it, training_loss=0.153]\u001b[A\n",
            "Epoch8:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 20/40 [00:29<00:29,  1.47s/it, training_loss=0.153]\u001b[A\n",
            "Epoch8:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 20/40 [00:30<00:29,  1.47s/it, training_loss=0.065]\u001b[A\n",
            "Epoch8:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 21/40 [00:30<00:27,  1.47s/it, training_loss=0.065]\u001b[A\n",
            "Epoch8:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 21/40 [00:32<00:27,  1.47s/it, training_loss=0.110]\u001b[A\n",
            "Epoch8:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 22/40 [00:32<00:26,  1.47s/it, training_loss=0.110]\u001b[A\n",
            "Epoch8:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 22/40 [00:33<00:26,  1.47s/it, training_loss=0.074]\u001b[A\n",
            "Epoch8:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 23/40 [00:33<00:24,  1.47s/it, training_loss=0.074]\u001b[A\n",
            "Epoch8:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 23/40 [00:35<00:24,  1.47s/it, training_loss=0.057]\u001b[A\n",
            "Epoch8:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 24/40 [00:35<00:23,  1.47s/it, training_loss=0.057]\u001b[A\n",
            "Epoch8:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 24/40 [00:36<00:23,  1.47s/it, training_loss=0.125]\u001b[A\n",
            "Epoch8:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 25/40 [00:36<00:22,  1.47s/it, training_loss=0.125]\u001b[A\n",
            "Epoch8:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 25/40 [00:38<00:22,  1.47s/it, training_loss=0.187]\u001b[A\n",
            "Epoch8:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 26/40 [00:38<00:20,  1.47s/it, training_loss=0.187]\u001b[A\n",
            "Epoch8:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 26/40 [00:39<00:20,  1.47s/it, training_loss=0.093]\u001b[A\n",
            "Epoch8:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 27/40 [00:39<00:19,  1.47s/it, training_loss=0.093]\u001b[A\n",
            "Epoch8:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 27/40 [00:41<00:19,  1.47s/it, training_loss=0.112]\u001b[A\n",
            "Epoch8:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 28/40 [00:41<00:17,  1.47s/it, training_loss=0.112]\u001b[A\n",
            "Epoch8:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 28/40 [00:42<00:17,  1.47s/it, training_loss=0.058]\u001b[A\n",
            "Epoch8:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 29/40 [00:42<00:16,  1.47s/it, training_loss=0.058]\u001b[A\n",
            "Epoch8:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 29/40 [00:44<00:16,  1.47s/it, training_loss=0.129]\u001b[A\n",
            "Epoch8:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 30/40 [00:44<00:14,  1.47s/it, training_loss=0.129]\u001b[A\n",
            "Epoch8:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 30/40 [00:45<00:14,  1.47s/it, training_loss=0.042]\u001b[A\n",
            "Epoch8:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 31/40 [00:45<00:13,  1.47s/it, training_loss=0.042]\u001b[A\n",
            "Epoch8:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 31/40 [00:47<00:13,  1.47s/it, training_loss=0.039]\u001b[A\n",
            "Epoch8:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 32/40 [00:47<00:11,  1.47s/it, training_loss=0.039]\u001b[A\n",
            "Epoch8:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 32/40 [00:48<00:11,  1.47s/it, training_loss=0.162]\u001b[A\n",
            "Epoch8:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 33/40 [00:48<00:10,  1.47s/it, training_loss=0.162]\u001b[A\n",
            "Epoch8:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 33/40 [00:49<00:10,  1.47s/it, training_loss=0.169]\u001b[A\n",
            "Epoch8:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 34/40 [00:49<00:08,  1.47s/it, training_loss=0.169]\u001b[A\n",
            "Epoch8:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 34/40 [00:51<00:08,  1.47s/it, training_loss=0.199]\u001b[A\n",
            "Epoch8:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 35/40 [00:51<00:07,  1.47s/it, training_loss=0.199]\u001b[A\n",
            "Epoch8:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 35/40 [00:52<00:07,  1.47s/it, training_loss=0.063]\u001b[A\n",
            "Epoch8:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 36/40 [00:52<00:05,  1.47s/it, training_loss=0.063]\u001b[A\n",
            "Epoch8:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 36/40 [00:54<00:05,  1.47s/it, training_loss=0.113]\u001b[A\n",
            "Epoch8:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 37/40 [00:54<00:04,  1.48s/it, training_loss=0.113]\u001b[A\n",
            "Epoch8:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 37/40 [00:55<00:04,  1.48s/it, training_loss=0.150]\u001b[A\n",
            "Epoch8:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 38/40 [00:55<00:02,  1.48s/it, training_loss=0.150]\u001b[A\n",
            "Epoch8:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 38/40 [00:57<00:02,  1.48s/it, training_loss=0.084]\u001b[A\n",
            "Epoch8:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 39/40 [00:57<00:01,  1.48s/it, training_loss=0.084]\u001b[A\n",
            "Epoch8:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 39/40 [00:57<00:01,  1.48s/it, training_loss=0.205]\u001b[A\n",
            "Epoch8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:57<00:00,  1.19s/it, training_loss=0.205]\u001b[A\n",
            " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [07:36<01:54, 57.36s/it]\n",
            "Epoch9:   0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch9:   0%|          | 0/40 [00:01<?, ?it/s, training_loss=0.159]\u001b[A\n",
            "Epoch9:   2%|â–Ž         | 1/40 [00:01<00:57,  1.48s/it, training_loss=0.159]\u001b[A\n",
            "Epoch9:   2%|â–Ž         | 1/40 [00:02<00:57,  1.48s/it, training_loss=0.165]\u001b[A\n",
            "Epoch9:   5%|â–Œ         | 2/40 [00:02<00:56,  1.48s/it, training_loss=0.165]\u001b[A\n",
            "Epoch9:   5%|â–Œ         | 2/40 [00:04<00:56,  1.48s/it, training_loss=0.149]\u001b[A\n",
            "Epoch9:   8%|â–Š         | 3/40 [00:04<00:54,  1.48s/it, training_loss=0.149]\u001b[A\n",
            "Epoch9:   8%|â–Š         | 3/40 [00:05<00:54,  1.48s/it, training_loss=0.100]\u001b[A\n",
            "Epoch9:  10%|â–ˆ         | 4/40 [00:05<00:53,  1.48s/it, training_loss=0.100]\u001b[A\n",
            "Epoch9:  10%|â–ˆ         | 4/40 [00:07<00:53,  1.48s/it, training_loss=0.105]\u001b[A\n",
            "Epoch9:  12%|â–ˆâ–Ž        | 5/40 [00:07<00:51,  1.48s/it, training_loss=0.105]\u001b[A\n",
            "Epoch9:  12%|â–ˆâ–Ž        | 5/40 [00:08<00:51,  1.48s/it, training_loss=0.098]\u001b[A\n",
            "Epoch9:  15%|â–ˆâ–Œ        | 6/40 [00:08<00:50,  1.47s/it, training_loss=0.098]\u001b[A\n",
            "Epoch9:  15%|â–ˆâ–Œ        | 6/40 [00:10<00:50,  1.47s/it, training_loss=0.139]\u001b[A\n",
            "Epoch9:  18%|â–ˆâ–Š        | 7/40 [00:10<00:48,  1.47s/it, training_loss=0.139]\u001b[A\n",
            "Epoch9:  18%|â–ˆâ–Š        | 7/40 [00:11<00:48,  1.47s/it, training_loss=0.100]\u001b[A\n",
            "Epoch9:  20%|â–ˆâ–ˆ        | 8/40 [00:11<00:47,  1.48s/it, training_loss=0.100]\u001b[A\n",
            "Epoch9:  20%|â–ˆâ–ˆ        | 8/40 [00:13<00:47,  1.48s/it, training_loss=0.054]\u001b[A\n",
            "Epoch9:  22%|â–ˆâ–ˆâ–Ž       | 9/40 [00:13<00:45,  1.47s/it, training_loss=0.054]\u001b[A\n",
            "Epoch9:  22%|â–ˆâ–ˆâ–Ž       | 9/40 [00:14<00:45,  1.47s/it, training_loss=0.126]\u001b[A\n",
            "Epoch9:  25%|â–ˆâ–ˆâ–Œ       | 10/40 [00:14<00:44,  1.47s/it, training_loss=0.126]\u001b[A\n",
            "Epoch9:  25%|â–ˆâ–ˆâ–Œ       | 10/40 [00:16<00:44,  1.47s/it, training_loss=0.033]\u001b[A\n",
            "Epoch9:  28%|â–ˆâ–ˆâ–Š       | 11/40 [00:16<00:42,  1.47s/it, training_loss=0.033]\u001b[A\n",
            "Epoch9:  28%|â–ˆâ–ˆâ–Š       | 11/40 [00:17<00:42,  1.47s/it, training_loss=0.133]\u001b[A\n",
            "Epoch9:  30%|â–ˆâ–ˆâ–ˆ       | 12/40 [00:17<00:41,  1.47s/it, training_loss=0.133]\u001b[A\n",
            "Epoch9:  30%|â–ˆâ–ˆâ–ˆ       | 12/40 [00:19<00:41,  1.47s/it, training_loss=0.034]\u001b[A\n",
            "Epoch9:  32%|â–ˆâ–ˆâ–ˆâ–Ž      | 13/40 [00:19<00:39,  1.47s/it, training_loss=0.034]\u001b[A\n",
            "Epoch9:  32%|â–ˆâ–ˆâ–ˆâ–Ž      | 13/40 [00:20<00:39,  1.47s/it, training_loss=0.059]\u001b[A\n",
            "Epoch9:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 14/40 [00:20<00:38,  1.47s/it, training_loss=0.059]\u001b[A\n",
            "Epoch9:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 14/40 [00:22<00:38,  1.47s/it, training_loss=0.049]\u001b[A\n",
            "Epoch9:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 15/40 [00:22<00:36,  1.47s/it, training_loss=0.049]\u001b[A\n",
            "Epoch9:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 15/40 [00:23<00:36,  1.47s/it, training_loss=0.050]\u001b[A\n",
            "Epoch9:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 16/40 [00:23<00:35,  1.47s/it, training_loss=0.050]\u001b[A\n",
            "Epoch9:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 16/40 [00:25<00:35,  1.47s/it, training_loss=0.183]\u001b[A\n",
            "Epoch9:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 17/40 [00:25<00:33,  1.47s/it, training_loss=0.183]\u001b[A\n",
            "Epoch9:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 17/40 [00:26<00:33,  1.47s/it, training_loss=0.101]\u001b[A\n",
            "Epoch9:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 18/40 [00:26<00:32,  1.47s/it, training_loss=0.101]\u001b[A\n",
            "Epoch9:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 18/40 [00:27<00:32,  1.47s/it, training_loss=0.157]\u001b[A\n",
            "Epoch9:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 19/40 [00:27<00:30,  1.47s/it, training_loss=0.157]\u001b[A\n",
            "Epoch9:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 19/40 [00:29<00:30,  1.47s/it, training_loss=0.139]\u001b[A\n",
            "Epoch9:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 20/40 [00:29<00:29,  1.47s/it, training_loss=0.139]\u001b[A\n",
            "Epoch9:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 20/40 [00:30<00:29,  1.47s/it, training_loss=0.119]\u001b[A\n",
            "Epoch9:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 21/40 [00:30<00:27,  1.47s/it, training_loss=0.119]\u001b[A\n",
            "Epoch9:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 21/40 [00:32<00:27,  1.47s/it, training_loss=0.108]\u001b[A\n",
            "Epoch9:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 22/40 [00:32<00:26,  1.47s/it, training_loss=0.108]\u001b[A\n",
            "Epoch9:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 22/40 [00:33<00:26,  1.47s/it, training_loss=0.108]\u001b[A\n",
            "Epoch9:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 23/40 [00:33<00:25,  1.47s/it, training_loss=0.108]\u001b[A\n",
            "Epoch9:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 23/40 [00:35<00:25,  1.47s/it, training_loss=0.177]\u001b[A\n",
            "Epoch9:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 24/40 [00:35<00:23,  1.47s/it, training_loss=0.177]\u001b[A\n",
            "Epoch9:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 24/40 [00:36<00:23,  1.47s/it, training_loss=0.116]\u001b[A\n",
            "Epoch9:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 25/40 [00:36<00:22,  1.47s/it, training_loss=0.116]\u001b[A\n",
            "Epoch9:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 25/40 [00:38<00:22,  1.47s/it, training_loss=0.175]\u001b[A\n",
            "Epoch9:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 26/40 [00:38<00:20,  1.47s/it, training_loss=0.175]\u001b[A\n",
            "Epoch9:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 26/40 [00:39<00:20,  1.47s/it, training_loss=0.154]\u001b[A\n",
            "Epoch9:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 27/40 [00:39<00:19,  1.47s/it, training_loss=0.154]\u001b[A\n",
            "Epoch9:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 27/40 [00:41<00:19,  1.47s/it, training_loss=0.094]\u001b[A\n",
            "Epoch9:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 28/40 [00:41<00:17,  1.47s/it, training_loss=0.094]\u001b[A\n",
            "Epoch9:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 28/40 [00:42<00:17,  1.47s/it, training_loss=0.096]\u001b[A\n",
            "Epoch9:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 29/40 [00:42<00:16,  1.48s/it, training_loss=0.096]\u001b[A\n",
            "Epoch9:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 29/40 [00:44<00:16,  1.48s/it, training_loss=0.087]\u001b[A\n",
            "Epoch9:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 30/40 [00:44<00:14,  1.48s/it, training_loss=0.087]\u001b[A\n",
            "Epoch9:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 30/40 [00:45<00:14,  1.48s/it, training_loss=0.064]\u001b[A\n",
            "Epoch9:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 31/40 [00:45<00:13,  1.48s/it, training_loss=0.064]\u001b[A\n",
            "Epoch9:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 31/40 [00:47<00:13,  1.48s/it, training_loss=0.082]\u001b[A\n",
            "Epoch9:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 32/40 [00:47<00:11,  1.48s/it, training_loss=0.082]\u001b[A\n",
            "Epoch9:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 32/40 [00:48<00:11,  1.48s/it, training_loss=0.047]\u001b[A\n",
            "Epoch9:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 33/40 [00:48<00:10,  1.48s/it, training_loss=0.047]\u001b[A\n",
            "Epoch9:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 33/40 [00:50<00:10,  1.48s/it, training_loss=0.159]\u001b[A\n",
            "Epoch9:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 34/40 [00:50<00:08,  1.48s/it, training_loss=0.159]\u001b[A\n",
            "Epoch9:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 34/40 [00:51<00:08,  1.48s/it, training_loss=0.105]\u001b[A\n",
            "Epoch9:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 35/40 [00:51<00:07,  1.48s/it, training_loss=0.105]\u001b[A\n",
            "Epoch9:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 35/40 [00:53<00:07,  1.48s/it, training_loss=0.049]\u001b[A\n",
            "Epoch9:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 36/40 [00:53<00:05,  1.48s/it, training_loss=0.049]\u001b[A\n",
            "Epoch9:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 36/40 [00:54<00:05,  1.48s/it, training_loss=0.183]\u001b[A\n",
            "Epoch9:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 37/40 [00:54<00:04,  1.48s/it, training_loss=0.183]\u001b[A\n",
            "Epoch9:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 37/40 [00:56<00:04,  1.48s/it, training_loss=0.101]\u001b[A\n",
            "Epoch9:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 38/40 [00:56<00:02,  1.48s/it, training_loss=0.101]\u001b[A\n",
            "Epoch9:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 38/40 [00:57<00:02,  1.48s/it, training_loss=0.056]\u001b[A\n",
            "Epoch9:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 39/40 [00:57<00:01,  1.48s/it, training_loss=0.056]\u001b[A\n",
            "Epoch9:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 39/40 [00:58<00:01,  1.48s/it, training_loss=0.075]\u001b[A\n",
            "Epoch9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:58<00:00,  1.19s/it, training_loss=0.075]\u001b[A\n",
            " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [08:34<00:57, 57.57s/it]\n",
            "Epoch10:   0%|          | 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Epoch10:   0%|          | 0/40 [00:01<?, ?it/s, training_loss=0.075]\u001b[A\n",
            "Epoch10:   2%|â–Ž         | 1/40 [00:01<00:57,  1.47s/it, training_loss=0.075]\u001b[A\n",
            "Epoch10:   2%|â–Ž         | 1/40 [00:02<00:57,  1.47s/it, training_loss=0.106]\u001b[A\n",
            "Epoch10:   5%|â–Œ         | 2/40 [00:02<00:55,  1.47s/it, training_loss=0.106]\u001b[A\n",
            "Epoch10:   5%|â–Œ         | 2/40 [00:04<00:55,  1.47s/it, training_loss=0.149]\u001b[A\n",
            "Epoch10:   8%|â–Š         | 3/40 [00:04<00:54,  1.47s/it, training_loss=0.149]\u001b[A\n",
            "Epoch10:   8%|â–Š         | 3/40 [00:05<00:54,  1.47s/it, training_loss=0.130]\u001b[A\n",
            "Epoch10:  10%|â–ˆ         | 4/40 [00:05<00:52,  1.47s/it, training_loss=0.130]\u001b[A\n",
            "Epoch10:  10%|â–ˆ         | 4/40 [00:07<00:52,  1.47s/it, training_loss=0.036]\u001b[A\n",
            "Epoch10:  12%|â–ˆâ–Ž        | 5/40 [00:07<00:51,  1.47s/it, training_loss=0.036]\u001b[A\n",
            "Epoch10:  12%|â–ˆâ–Ž        | 5/40 [00:08<00:51,  1.47s/it, training_loss=0.160]\u001b[A\n",
            "Epoch10:  15%|â–ˆâ–Œ        | 6/40 [00:08<00:49,  1.47s/it, training_loss=0.160]\u001b[A\n",
            "Epoch10:  15%|â–ˆâ–Œ        | 6/40 [00:10<00:49,  1.47s/it, training_loss=0.180]\u001b[A\n",
            "Epoch10:  18%|â–ˆâ–Š        | 7/40 [00:10<00:48,  1.48s/it, training_loss=0.180]\u001b[A\n",
            "Epoch10:  18%|â–ˆâ–Š        | 7/40 [00:11<00:48,  1.48s/it, training_loss=0.055]\u001b[A\n",
            "Epoch10:  20%|â–ˆâ–ˆ        | 8/40 [00:11<00:47,  1.47s/it, training_loss=0.055]\u001b[A\n",
            "Epoch10:  20%|â–ˆâ–ˆ        | 8/40 [00:13<00:47,  1.47s/it, training_loss=0.097]\u001b[A\n",
            "Epoch10:  22%|â–ˆâ–ˆâ–Ž       | 9/40 [00:13<00:45,  1.47s/it, training_loss=0.097]\u001b[A\n",
            "Epoch10:  22%|â–ˆâ–ˆâ–Ž       | 9/40 [00:14<00:45,  1.47s/it, training_loss=0.113]\u001b[A\n",
            "Epoch10:  25%|â–ˆâ–ˆâ–Œ       | 10/40 [00:14<00:44,  1.48s/it, training_loss=0.113]\u001b[A\n",
            "Epoch10:  25%|â–ˆâ–ˆâ–Œ       | 10/40 [00:16<00:44,  1.48s/it, training_loss=0.072]\u001b[A\n",
            "Epoch10:  28%|â–ˆâ–ˆâ–Š       | 11/40 [00:16<00:42,  1.47s/it, training_loss=0.072]\u001b[A\n",
            "Epoch10:  28%|â–ˆâ–ˆâ–Š       | 11/40 [00:17<00:42,  1.47s/it, training_loss=0.108]\u001b[A\n",
            "Epoch10:  30%|â–ˆâ–ˆâ–ˆ       | 12/40 [00:17<00:41,  1.47s/it, training_loss=0.108]\u001b[A\n",
            "Epoch10:  30%|â–ˆâ–ˆâ–ˆ       | 12/40 [00:19<00:41,  1.47s/it, training_loss=0.039]\u001b[A\n",
            "Epoch10:  32%|â–ˆâ–ˆâ–ˆâ–Ž      | 13/40 [00:19<00:39,  1.47s/it, training_loss=0.039]\u001b[A\n",
            "Epoch10:  32%|â–ˆâ–ˆâ–ˆâ–Ž      | 13/40 [00:20<00:39,  1.47s/it, training_loss=0.151]\u001b[A\n",
            "Epoch10:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 14/40 [00:20<00:38,  1.47s/it, training_loss=0.151]\u001b[A\n",
            "Epoch10:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 14/40 [00:22<00:38,  1.47s/it, training_loss=0.111]\u001b[A\n",
            "Epoch10:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 15/40 [00:22<00:36,  1.47s/it, training_loss=0.111]\u001b[A\n",
            "Epoch10:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 15/40 [00:23<00:36,  1.47s/it, training_loss=0.031]\u001b[A\n",
            "Epoch10:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 16/40 [00:23<00:35,  1.47s/it, training_loss=0.031]\u001b[A\n",
            "Epoch10:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 16/40 [00:25<00:35,  1.47s/it, training_loss=0.103]\u001b[A\n",
            "Epoch10:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 17/40 [00:25<00:33,  1.47s/it, training_loss=0.103]\u001b[A\n",
            "Epoch10:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 17/40 [00:26<00:33,  1.47s/it, training_loss=0.104]\u001b[A\n",
            "Epoch10:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 18/40 [00:26<00:32,  1.47s/it, training_loss=0.104]\u001b[A\n",
            "Epoch10:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 18/40 [00:27<00:32,  1.47s/it, training_loss=0.085]\u001b[A\n",
            "Epoch10:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 19/40 [00:27<00:30,  1.47s/it, training_loss=0.085]\u001b[A\n",
            "Epoch10:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 19/40 [00:29<00:30,  1.47s/it, training_loss=0.073]\u001b[A\n",
            "Epoch10:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 20/40 [00:29<00:29,  1.48s/it, training_loss=0.073]\u001b[A\n",
            "Epoch10:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 20/40 [00:30<00:29,  1.48s/it, training_loss=0.125]\u001b[A\n",
            "Epoch10:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 21/40 [00:30<00:27,  1.47s/it, training_loss=0.125]\u001b[A\n",
            "Epoch10:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 21/40 [00:32<00:27,  1.47s/it, training_loss=0.179]\u001b[A\n",
            "Epoch10:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 22/40 [00:32<00:26,  1.47s/it, training_loss=0.179]\u001b[A\n",
            "Epoch10:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 22/40 [00:33<00:26,  1.47s/it, training_loss=0.131]\u001b[A\n",
            "Epoch10:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 23/40 [00:33<00:25,  1.47s/it, training_loss=0.131]\u001b[A\n",
            "Epoch10:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 23/40 [00:35<00:25,  1.47s/it, training_loss=0.090]\u001b[A\n",
            "Epoch10:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 24/40 [00:35<00:23,  1.47s/it, training_loss=0.090]\u001b[A\n",
            "Epoch10:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 24/40 [00:36<00:23,  1.47s/it, training_loss=0.123]\u001b[A\n",
            "Epoch10:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 25/40 [00:36<00:22,  1.47s/it, training_loss=0.123]\u001b[A\n",
            "Epoch10:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 25/40 [00:38<00:22,  1.47s/it, training_loss=0.153]\u001b[A\n",
            "Epoch10:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 26/40 [00:38<00:20,  1.47s/it, training_loss=0.153]\u001b[A\n",
            "Epoch10:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 26/40 [00:39<00:20,  1.47s/it, training_loss=0.165]\u001b[A\n",
            "Epoch10:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 27/40 [00:39<00:19,  1.47s/it, training_loss=0.165]\u001b[A\n",
            "Epoch10:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 27/40 [00:41<00:19,  1.47s/it, training_loss=0.063]\u001b[A\n",
            "Epoch10:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 28/40 [00:41<00:17,  1.47s/it, training_loss=0.063]\u001b[A\n",
            "Epoch10:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 28/40 [00:42<00:17,  1.47s/it, training_loss=0.094]\u001b[A\n",
            "Epoch10:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 29/40 [00:42<00:16,  1.47s/it, training_loss=0.094]\u001b[A\n",
            "Epoch10:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 29/40 [00:44<00:16,  1.47s/it, training_loss=0.097]\u001b[A\n",
            "Epoch10:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 30/40 [00:44<00:14,  1.47s/it, training_loss=0.097]\u001b[A\n",
            "Epoch10:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 30/40 [00:45<00:14,  1.47s/it, training_loss=0.101]\u001b[A\n",
            "Epoch10:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 31/40 [00:45<00:13,  1.48s/it, training_loss=0.101]\u001b[A\n",
            "Epoch10:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 31/40 [00:47<00:13,  1.48s/it, training_loss=0.090]\u001b[A\n",
            "Epoch10:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 32/40 [00:47<00:11,  1.48s/it, training_loss=0.090]\u001b[A\n",
            "Epoch10:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 32/40 [00:48<00:11,  1.48s/it, training_loss=0.092]\u001b[A\n",
            "Epoch10:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 33/40 [00:48<00:10,  1.47s/it, training_loss=0.092]\u001b[A\n",
            "Epoch10:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 33/40 [00:50<00:10,  1.47s/it, training_loss=0.052]\u001b[A\n",
            "Epoch10:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 34/40 [00:50<00:08,  1.47s/it, training_loss=0.052]\u001b[A\n",
            "Epoch10:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 34/40 [00:51<00:08,  1.47s/it, training_loss=0.118]\u001b[A\n",
            "Epoch10:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 35/40 [00:51<00:07,  1.47s/it, training_loss=0.118]\u001b[A\n",
            "Epoch10:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 35/40 [00:53<00:07,  1.47s/it, training_loss=0.110]\u001b[A\n",
            "Epoch10:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 36/40 [00:53<00:05,  1.47s/it, training_loss=0.110]\u001b[A\n",
            "Epoch10:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 36/40 [00:54<00:05,  1.47s/it, training_loss=0.218]\u001b[A\n",
            "Epoch10:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 37/40 [00:54<00:04,  1.47s/it, training_loss=0.218]\u001b[A\n",
            "Epoch10:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 37/40 [00:55<00:04,  1.47s/it, training_loss=0.051]\u001b[A\n",
            "Epoch10:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 38/40 [00:55<00:02,  1.47s/it, training_loss=0.051]\u001b[A\n",
            "Epoch10:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 38/40 [00:57<00:02,  1.47s/it, training_loss=0.144]\u001b[A\n",
            "Epoch10:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 39/40 [00:57<00:01,  1.47s/it, training_loss=0.144]\u001b[A\n",
            "Epoch10:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 39/40 [00:57<00:01,  1.47s/it, training_loss=0.090]\u001b[A\n",
            "Epoch10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:57<00:00,  1.18s/it, training_loss=0.090]\u001b[A\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [09:32<00:00, 57.26s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-fcf39487c1cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34mf'Models/BERT_ft_epoch{epoch}.model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mtdqm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nEpoch {epoch}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mloss_train_avg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_train_total\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tdqm' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cjn27EfaSzka"
      },
      "source": [
        "model=BertForSequenceClassification.form_pretraind(\"bert-base-uncased\",\n",
        "num_labels =len(label_dict),\n",
        "output_attentions=False,\n",
        "output_hidden_states=False\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6paUSssSSzrm"
      },
      "source": [
        "model.to(device)\n",
        "pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4JjhZRNSzxG"
      },
      "source": [
        "model.load_state_dict(\n",
        "    torch.load('Models/finetuned_bert_epoch_1_gpu_trained.model'),\n",
        "    map_location=torch.device('cuda')\n",
        "\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQHYCYjRSzwL"
      },
      "source": [
        "_,prdictions,true_vals=evaluate(dataloader_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kDykWqwSzqa"
      },
      "source": [
        "accuracy_per_class(predictions,true_vals)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKflK5riNfZ_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0O__X-XGNfd_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YCAP-W3NfkW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zou8rtazNfoL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvUb2Pa-NfjS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}